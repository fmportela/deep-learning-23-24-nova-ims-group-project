{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref sobre transfer learning:\n",
    "https://keras.io/guides/transfer_learning/\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pydot\n",
    "# ! pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import optimizers\n",
    "import os\n",
    "from tensorflow.keras.utils import image_dataset_from_directory # type: ignore\n",
    "from tensorflow.keras.metrics import (F1Score, Precision, Recall, CategoricalAccuracy,  # type: ignore\n",
    "                                      TruePositives, TrueNegatives, FalsePositives, FalseNegatives) \n",
    "import yaml\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential, layers, initializers, regularizers, optimizers, metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicParams = {}\n",
    "dicParams[\"model_name\"] = \"base_03\"\n",
    "dicParams[\"model_description\"]\t= \"base_03, 150x150, 4Conv, 2MaxPool, 1Dense, 2Dropout, 1Sigmoid, RMSprop(lr=0.001)\"\n",
    "\n",
    "dicParams[\"batch_size\"] = 256\n",
    "#dicParams[\"image_size\"] = (150,150)\n",
    "dicParams[\"image_size\"] = (128,128)\n",
    "dicParams[\"input_shape\"] = dicParams[\"image_size\"] + (3,)\n",
    "#dicParams[\"image_size\"] = (260,225)\n",
    "dicParams[\"epochs\"] = 50\n",
    "dicParams[\"learning_rate\"] = 1e-3\n",
    "\n",
    "dicParams[\"steps_per_epoch\"] = 32\n",
    "dicParams[\"validation_steps\"] = 2\n",
    "dicParams[\"interpolation\"] = \"bilinear\"\n",
    "dicParams[\"color_mode\"] = \"rgb\"\n",
    "\n",
    "dicParams[\"labels\"] = \"inferred\"\n",
    "dicParams[\"seed\"] = 42\n",
    "dicParams[\"crop_to_aspect_ratio\"] = True\n",
    "\n",
    "# dicParams[\"num_classes\"] = 6\n",
    "# dicParams[\"start_dir\"] = \"smalldata\"\n",
    "dicParams[\"num_classes\"] = 114\n",
    "dicParams[\"start_dir\"] = \"data\"\n",
    "\n",
    "#IMAGE_SIZE = (244, 244)\n",
    "#IMAGE_SIZE = (150,150) # - First baseline run\n",
    "# - First baseline run - BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11556 files belonging to 114 classes.\n",
      "Found 2477 files belonging to 114 classes.\n",
      "Found 2477 files belonging to 114 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dicParams[\"start_dir\"], 'train')\n",
    "val_path = os.path.join(dicParams[\"start_dir\"], 'val')\n",
    "test_path = os.path.join(dicParams[\"start_dir\"], 'test')\n",
    "\n",
    "\n",
    "# with the exception of the directory arg all\n",
    "# other args will be the same for each set\n",
    "import_kwargs = {\n",
    "    'labels': dicParams[\"labels\"],\n",
    "    'label_mode': 'categorical',  # if 'categorical' use 'categorical_crossentropy', if 'int' use 'sparse_categorical_crossentropy'\n",
    "    'color_mode': 'rgb',\n",
    "    'batch_size': dicParams[\"batch_size\"],\n",
    "    'image_size': dicParams[\"image_size\"],\n",
    "    'seed': dicParams[\"seed\"],\n",
    "    'interpolation': dicParams[\"interpolation\"],\n",
    "    'crop_to_aspect_ratio': dicParams[\"crop_to_aspect_ratio\"]\n",
    "}\n",
    "\n",
    "\n",
    "# this function returns a tf.data.Dataset object\n",
    "train_data = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    shuffle=True,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "val_data = image_dataset_from_directory(\n",
    "    val_path,\n",
    "    shuffle=False,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    shuffle=False,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "# making sure all partitions have the same labels in the same order\n",
    "assert train_data.class_names == val_data.class_names == test_data.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an object of type tf.data.Dataset \n",
    "ds_train = train_data\n",
    "\n",
    "ds_val = val_data\n",
    "\n",
    "ds_test = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 134, 134, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 64, 64, 64)           9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 66, 66, 64)           0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 32, 32, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 32, 32, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 32, 32, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 32, 32, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 32, 32, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 32, 32, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 32, 32, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 32, 32, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 32, 32, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 32, 32, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 32, 32, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 32, 32, 256)          1024      ['conv2_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 32, 32, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 32, 32, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 16, 16, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 16, 16, 256)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 16, 16, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 16, 16, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 16, 16, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 16, 16, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 16, 16, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 16, 16, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 16, 16, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 8, 8, 128)            147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 512)            0         ['conv3_block3_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 8, 8, 512)            0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 8, 8, 512)            2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 8, 8, 512)            0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 8, 8, 256)            131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 8, 8, 1024)           525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block6_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block6_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 4, 4, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 4, 4, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 4, 4, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 1024)           0         ['conv4_block5_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 4, 4, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)      (None, 4, 4, 1024)           0         ['max_pooling2d_2[0][0]',     \n",
      "                                                                     'conv4_block6_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (Ba  (None, 4, 4, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (  (None, 4, 4, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524288    ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
      "                                                                     'conv5_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalizatio  (None, 4, 4, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " post_relu (Activation)      (None, 4, 4, 2048)           0         ['post_bn[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23564800 (89.89 MB)\n",
      "Trainable params: 23519360 (89.72 MB)\n",
      "Non-trainable params: 45440 (177.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"inception_resnet_v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 63, 63, 32)           864       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 63, 63, 32)           96        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 63, 63, 32)           0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)           9216      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 61, 61, 32)           96        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 61, 61, 32)           0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 61, 61, 64)           18432     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 61, 61, 64)           192       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 61, 61, 64)           0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 30, 30, 64)           0         ['activation_2[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 80)           5120      ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 30, 30, 80)           240       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 30, 30, 80)           0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 192)          138240    ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 28, 28, 192)          576       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 28, 28, 192)          0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 192)          0         ['activation_4[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 64)           12288     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 13, 13, 64)           192       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 13, 13, 64)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 13, 13, 48)           9216      ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 13, 13, 96)           55296     ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 13, 13, 48)           144       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 13, 13, 96)           288       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 13, 13, 48)           0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 13, 13, 96)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 13, 13, 192)          0         ['max_pooling2d_4[0][0]']     \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 96)           18432     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 64)           76800     ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 13, 13, 96)           82944     ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 13, 13, 64)           12288     ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 13, 13, 96)           288       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 13, 13, 64)           192       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 13, 13, 96)           288       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 13, 13, 64)           192       ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 13, 13, 96)           0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 13, 13, 64)           0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 13, 13, 96)           0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " mixed_5b (Concatenate)      (None, 13, 13, 320)          0         ['activation_5[0][0]',        \n",
      "                                                                     'activation_7[0][0]',        \n",
      "                                                                     'activation_10[0][0]',       \n",
      "                                                                     'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 13, 13, 32)           10240     ['mixed_5b[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 13, 13, 32)           96        ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 13, 13, 32)           10240     ['mixed_5b[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 13, 13, 32)           96        ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 13, 13, 48)           144       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 13, 13, 32)           10240     ['mixed_5b[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 13, 13, 32)           96        ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 13, 13, 32)           96        ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 13, 13, 64)           192       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_1_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_12[0][0]',       \n",
      " te)                                                                 'activation_14[0][0]',       \n",
      "                                                                     'activation_17[0][0]']       \n",
      "                                                                                                  \n",
      " block35_1_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_1_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer (Custom  (None, 13, 13, 320)          0         ['mixed_5b[0][0]',            \n",
      " ScaleLayer)                                                         'block35_1_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_1_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_1_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 13, 13, 32)           96        ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_1_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 13, 13, 32)           96        ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 13, 13, 48)           144       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_1_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 13, 13, 32)           96        ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 13, 13, 32)           96        ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 13, 13, 64)           192       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_2_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_18[0][0]',       \n",
      " te)                                                                 'activation_20[0][0]',       \n",
      "                                                                     'activation_23[0][0]']       \n",
      "                                                                                                  \n",
      " block35_2_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_2_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_1 (Cust  (None, 13, 13, 320)          0         ['block35_1_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_2_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_1[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_2_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 13, 13, 32)           96        ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_2_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 13, 13, 32)           96        ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 13, 13, 48)           144       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_2_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 13, 13, 32)           96        ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 13, 13, 32)           96        ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 13, 13, 64)           192       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_3_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_24[0][0]',       \n",
      " te)                                                                 'activation_26[0][0]',       \n",
      "                                                                     'activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " block35_3_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_3_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_2 (Cust  (None, 13, 13, 320)          0         ['block35_2_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_3_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_2[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_3_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 13, 13, 32)           96        ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_3_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 13, 13, 32)           96        ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 13, 13, 48)           144       ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_3_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 13, 13, 32)           96        ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 13, 13, 32)           96        ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 13, 13, 64)           192       ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_4_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_30[0][0]',       \n",
      " te)                                                                 'activation_32[0][0]',       \n",
      "                                                                     'activation_35[0][0]']       \n",
      "                                                                                                  \n",
      " block35_4_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_4_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_3 (Cust  (None, 13, 13, 320)          0         ['block35_3_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_4_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_3[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_4_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 13, 13, 32)           96        ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_4_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 13, 13, 32)           96        ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 13, 13, 48)           144       ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_4_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_40[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 13, 13, 32)           96        ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 13, 13, 32)           96        ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 13, 13, 64)           192       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_5_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_36[0][0]',       \n",
      " te)                                                                 'activation_38[0][0]',       \n",
      "                                                                     'activation_41[0][0]']       \n",
      "                                                                                                  \n",
      " block35_5_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_5_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_4 (Cust  (None, 13, 13, 320)          0         ['block35_4_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_5_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_4[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_5_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 13, 13, 32)           96        ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_5_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_45[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 13, 13, 32)           96        ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 13, 13, 48)           144       ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_5_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 13, 13, 32)           96        ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 13, 13, 32)           96        ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 13, 13, 64)           192       ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_6_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_42[0][0]',       \n",
      " te)                                                                 'activation_44[0][0]',       \n",
      "                                                                     'activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " block35_6_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_6_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_5 (Cust  (None, 13, 13, 320)          0         ['block35_5_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_6_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_6_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_5[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_6_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 13, 13, 32)           96        ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_6_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 13, 13, 32)           96        ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_52 (Ba  (None, 13, 13, 48)           144       ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_52[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_6_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 13, 13, 32)           96        ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 13, 13, 32)           96        ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_53 (Ba  (None, 13, 13, 64)           192       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_53[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_7_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_48[0][0]',       \n",
      " te)                                                                 'activation_50[0][0]',       \n",
      "                                                                     'activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " block35_7_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_7_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_6 (Cust  (None, 13, 13, 320)          0         ['block35_6_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_7_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_7_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_6[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_7_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_57 (Ba  (None, 13, 13, 32)           96        ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_57[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_7_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_57[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_55 (Ba  (None, 13, 13, 32)           96        ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_58 (Ba  (None, 13, 13, 48)           144       ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_55[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_58[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_7_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_54 (Ba  (None, 13, 13, 32)           96        ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_56 (Ba  (None, 13, 13, 32)           96        ['conv2d_56[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_59 (Ba  (None, 13, 13, 64)           192       ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_54[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_56[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_59[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_8_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_54[0][0]',       \n",
      " te)                                                                 'activation_56[0][0]',       \n",
      "                                                                     'activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " block35_8_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_8_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_7 (Cust  (None, 13, 13, 320)          0         ['block35_7_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_8_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_8_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_7[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_8_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_63 (Ba  (None, 13, 13, 32)           96        ['conv2d_63[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_63[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_8_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_63[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (Ba  (None, 13, 13, 32)           96        ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_64 (Ba  (None, 13, 13, 48)           144       ['conv2d_64[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_61[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_64[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_8_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_60 (Ba  (None, 13, 13, 32)           96        ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_62 (Ba  (None, 13, 13, 32)           96        ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_65 (Ba  (None, 13, 13, 64)           192       ['conv2d_65[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_60[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_62[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_65[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_9_mixed (Concatena  (None, 13, 13, 128)          0         ['activation_60[0][0]',       \n",
      " te)                                                                 'activation_62[0][0]',       \n",
      "                                                                     'activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " block35_9_conv (Conv2D)     (None, 13, 13, 320)          41280     ['block35_9_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_8 (Cust  (None, 13, 13, 320)          0         ['block35_8_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_9_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block35_9_ac (Activation)   (None, 13, 13, 320)          0         ['custom_scale_layer_8[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_9_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_69 (Ba  (None, 13, 13, 32)           96        ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_69[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_9_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 13, 13, 48)           13824     ['activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_67 (Ba  (None, 13, 13, 32)           96        ['conv2d_67[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_70 (Ba  (None, 13, 13, 48)           144       ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_67[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, 13, 13, 48)           0         ['batch_normalization_70[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)          (None, 13, 13, 32)           10240     ['block35_9_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)          (None, 13, 13, 32)           9216      ['activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 13, 13, 64)           27648     ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_66 (Ba  (None, 13, 13, 32)           96        ['conv2d_66[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_68 (Ba  (None, 13, 13, 32)           96        ['conv2d_68[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_71 (Ba  (None, 13, 13, 64)           192       ['conv2d_71[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_66[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, 13, 13, 32)           0         ['batch_normalization_68[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, 13, 13, 64)           0         ['batch_normalization_71[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block35_10_mixed (Concaten  (None, 13, 13, 128)          0         ['activation_66[0][0]',       \n",
      " ate)                                                                'activation_68[0][0]',       \n",
      "                                                                     'activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " block35_10_conv (Conv2D)    (None, 13, 13, 320)          41280     ['block35_10_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_9 (Cust  (None, 13, 13, 320)          0         ['block35_9_ac[0][0]',        \n",
      " omScaleLayer)                                                       'block35_10_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block35_10_ac (Activation)  (None, 13, 13, 320)          0         ['custom_scale_layer_9[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 13, 13, 256)          81920     ['block35_10_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_73 (Ba  (None, 13, 13, 256)          768       ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, 13, 13, 256)          0         ['batch_normalization_73[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 13, 13, 256)          589824    ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_74 (Ba  (None, 13, 13, 256)          768       ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, 13, 13, 256)          0         ['batch_normalization_74[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 6, 6, 384)            1105920   ['block35_10_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, 6, 6, 384)            884736    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_72 (Ba  (None, 6, 6, 384)            1152      ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_75 (Ba  (None, 6, 6, 384)            1152      ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, 6, 6, 384)            0         ['batch_normalization_72[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, 6, 6, 384)            0         ['batch_normalization_75[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 6, 6, 320)            0         ['block35_10_ac[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed_6a (Concatenate)      (None, 6, 6, 1088)           0         ['activation_72[0][0]',       \n",
      "                                                                     'activation_75[0][0]',       \n",
      "                                                                     'max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (None, 6, 6, 128)            139264    ['mixed_6a[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_77 (Ba  (None, 6, 6, 128)            384       ['conv2d_77[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_77[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_78 (Ba  (None, 6, 6, 160)            480       ['conv2d_78[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_78[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (None, 6, 6, 192)            208896    ['mixed_6a[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_78[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_76 (Ba  (None, 6, 6, 192)            576       ['conv2d_76[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_79 (Ba  (None, 6, 6, 192)            576       ['conv2d_79[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_76[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_79[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_1_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_76[0][0]',       \n",
      " te)                                                                 'activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " block17_1_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_1_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_10 (Cus  (None, 6, 6, 1088)           0         ['mixed_6a[0][0]',            \n",
      " tomScaleLayer)                                                      'block17_1_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_1_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_10[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (None, 6, 6, 128)            139264    ['block17_1_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (None, 6, 6, 128)            384       ['conv2d_81[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_81[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (None, 6, 6, 160)            480       ['conv2d_82[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_82[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (None, 6, 6, 192)            208896    ['block17_1_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_80 (Ba  (None, 6, 6, 192)            576       ['conv2d_80[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (None, 6, 6, 192)            576       ['conv2d_83[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_80[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_83[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_2_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_80[0][0]',       \n",
      " te)                                                                 'activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " block17_2_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_2_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_11 (Cus  (None, 6, 6, 1088)           0         ['block17_1_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_2_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_2_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_11[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, 6, 6, 128)            139264    ['block17_2_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (None, 6, 6, 128)            384       ['conv2d_85[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_85[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, 6, 6, 160)            480       ['conv2d_86[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (None, 6, 6, 192)            208896    ['block17_2_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (None, 6, 6, 192)            576       ['conv2d_84[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 6, 6, 192)            576       ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_84[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_3_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_84[0][0]',       \n",
      " te)                                                                 'activation_87[0][0]']       \n",
      "                                                                                                  \n",
      " block17_3_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_3_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_12 (Cus  (None, 6, 6, 1088)           0         ['block17_2_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_3_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_3_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_12[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 6, 6, 128)            139264    ['block17_3_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 6, 6, 128)            384       ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_89[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, 6, 6, 160)            480       ['conv2d_90[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 6, 6, 192)            208896    ['block17_3_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_90[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 6, 6, 192)            576       ['conv2d_88[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, 6, 6, 192)            576       ['conv2d_91[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_91 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_4_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_88[0][0]',       \n",
      " te)                                                                 'activation_91[0][0]']       \n",
      "                                                                                                  \n",
      " block17_4_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_4_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_13 (Cus  (None, 6, 6, 1088)           0         ['block17_3_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_4_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_4_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_13[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (None, 6, 6, 128)            139264    ['block17_4_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 6, 6, 128)            384       ['conv2d_93[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_93 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_93[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 6, 6, 160)            480       ['conv2d_94[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_94 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, 6, 6, 192)            208896    ['block17_4_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_94[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 6, 6, 192)            576       ['conv2d_92[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 6, 6, 192)            576       ['conv2d_95[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_92 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_5_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_92[0][0]',       \n",
      " te)                                                                 'activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " block17_5_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_5_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_14 (Cus  (None, 6, 6, 1088)           0         ['block17_4_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_5_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_5_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_14[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (None, 6, 6, 128)            139264    ['block17_5_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, 6, 6, 128)            384       ['conv2d_97[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, 6, 6, 128)            0         ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, 6, 6, 160)            143360    ['activation_97[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, 6, 6, 160)            480       ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_98 (Activation)  (None, 6, 6, 160)            0         ['batch_normalization_98[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (None, 6, 6, 192)            208896    ['block17_5_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, 6, 6, 192)            215040    ['activation_98[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, 6, 6, 192)            576       ['conv2d_96[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, 6, 6, 192)            576       ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_99 (Activation)  (None, 6, 6, 192)            0         ['batch_normalization_99[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block17_6_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_96[0][0]',       \n",
      " te)                                                                 'activation_99[0][0]']       \n",
      "                                                                                                  \n",
      " block17_6_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_6_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_15 (Cus  (None, 6, 6, 1088)           0         ['block17_5_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_6_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_6_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_15[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_6_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, 6, 6, 128)            384       ['conv2d_101[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_101 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_101[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, 6, 6, 160)            480       ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_102 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_6_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_102[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, 6, 6, 192)            576       ['conv2d_100[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, 6, 6, 192)            576       ['conv2d_103[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_100 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_103 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_103[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_7_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_100[0][0]',      \n",
      " te)                                                                 'activation_103[0][0]']      \n",
      "                                                                                                  \n",
      " block17_7_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_7_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_16 (Cus  (None, 6, 6, 1088)           0         ['block17_6_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_7_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_7_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_16[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_7_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, 6, 6, 128)            384       ['conv2d_105[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_105 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_105[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_105[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, 6, 6, 160)            480       ['conv2d_106[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_106 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_106[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_7_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_106[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, 6, 6, 192)            576       ['conv2d_104[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, 6, 6, 192)            576       ['conv2d_107[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_104 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_104[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_107 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_107[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_8_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_104[0][0]',      \n",
      " te)                                                                 'activation_107[0][0]']      \n",
      "                                                                                                  \n",
      " block17_8_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_8_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_17 (Cus  (None, 6, 6, 1088)           0         ['block17_7_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_8_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_8_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_17[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_8_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (None, 6, 6, 128)            384       ['conv2d_109[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_109 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_109[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_109[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (None, 6, 6, 160)            480       ['conv2d_110[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_110 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_110[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_8_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_110[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (None, 6, 6, 192)            576       ['conv2d_108[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (None, 6, 6, 192)            576       ['conv2d_111[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_108 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_108[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_111 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_111[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_9_mixed (Concatena  (None, 6, 6, 384)            0         ['activation_108[0][0]',      \n",
      " te)                                                                 'activation_111[0][0]']      \n",
      "                                                                                                  \n",
      " block17_9_conv (Conv2D)     (None, 6, 6, 1088)           418880    ['block17_9_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_18 (Cus  (None, 6, 6, 1088)           0         ['block17_8_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_9_conv[0][0]']      \n",
      "                                                                                                  \n",
      " block17_9_ac (Activation)   (None, 6, 6, 1088)           0         ['custom_scale_layer_18[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_9_ac[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (None, 6, 6, 128)            384       ['conv2d_113[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_113 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_113[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_113[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (None, 6, 6, 160)            480       ['conv2d_114[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_114 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_114[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_9_ac[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_114[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (None, 6, 6, 192)            576       ['conv2d_112[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_115 (B  (None, 6, 6, 192)            576       ['conv2d_115[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_112 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_112[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_115 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_115[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_10_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_112[0][0]',      \n",
      " ate)                                                                'activation_115[0][0]']      \n",
      "                                                                                                  \n",
      " block17_10_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_10_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_19 (Cus  (None, 6, 6, 1088)           0         ['block17_9_ac[0][0]',        \n",
      " tomScaleLayer)                                                      'block17_10_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_10_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_19[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_10_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_117 (B  (None, 6, 6, 128)            384       ['conv2d_117[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_117 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_117[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_117[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_118 (B  (None, 6, 6, 160)            480       ['conv2d_118[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_118 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_118[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_10_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_118[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_116 (B  (None, 6, 6, 192)            576       ['conv2d_116[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_119 (B  (None, 6, 6, 192)            576       ['conv2d_119[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_116 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_116[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_119 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_119[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_11_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_116[0][0]',      \n",
      " ate)                                                                'activation_119[0][0]']      \n",
      "                                                                                                  \n",
      " block17_11_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_11_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_20 (Cus  (None, 6, 6, 1088)           0         ['block17_10_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_11_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_11_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_20[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_11_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_121 (B  (None, 6, 6, 128)            384       ['conv2d_121[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_121 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_121[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_121[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_122 (B  (None, 6, 6, 160)            480       ['conv2d_122[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_122 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_122[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_11_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_122[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_120 (B  (None, 6, 6, 192)            576       ['conv2d_120[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_123 (B  (None, 6, 6, 192)            576       ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_120 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_120[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_123 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_123[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_12_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_120[0][0]',      \n",
      " ate)                                                                'activation_123[0][0]']      \n",
      "                                                                                                  \n",
      " block17_12_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_12_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_21 (Cus  (None, 6, 6, 1088)           0         ['block17_11_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_12_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_12_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_21[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_12_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_125 (B  (None, 6, 6, 128)            384       ['conv2d_125[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_125 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_125[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_125[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_126 (B  (None, 6, 6, 160)            480       ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_126 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_126[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_12_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_126[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_124 (B  (None, 6, 6, 192)            576       ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_127 (B  (None, 6, 6, 192)            576       ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_124 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_124[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_127 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_127[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_13_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_124[0][0]',      \n",
      " ate)                                                                'activation_127[0][0]']      \n",
      "                                                                                                  \n",
      " block17_13_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_13_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_22 (Cus  (None, 6, 6, 1088)           0         ['block17_12_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_13_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_13_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_22[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_13_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_129 (B  (None, 6, 6, 128)            384       ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_129 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_129[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_129[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_130 (B  (None, 6, 6, 160)            480       ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_130 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_130[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_13_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_130[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_128 (B  (None, 6, 6, 192)            576       ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_131 (B  (None, 6, 6, 192)            576       ['conv2d_131[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_128 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_128[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_131 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_131[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_14_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_128[0][0]',      \n",
      " ate)                                                                'activation_131[0][0]']      \n",
      "                                                                                                  \n",
      " block17_14_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_14_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_23 (Cus  (None, 6, 6, 1088)           0         ['block17_13_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_14_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_14_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_23[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_14_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_133 (B  (None, 6, 6, 128)            384       ['conv2d_133[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_133 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_133[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_133[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_134 (B  (None, 6, 6, 160)            480       ['conv2d_134[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_134 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_134[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_14_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_134[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_132 (B  (None, 6, 6, 192)            576       ['conv2d_132[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (None, 6, 6, 192)            576       ['conv2d_135[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_132 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_132[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_135 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_135[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_15_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_132[0][0]',      \n",
      " ate)                                                                'activation_135[0][0]']      \n",
      "                                                                                                  \n",
      " block17_15_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_15_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_24 (Cus  (None, 6, 6, 1088)           0         ['block17_14_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_15_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_15_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_24[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_15_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (None, 6, 6, 128)            384       ['conv2d_137[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_137 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_137[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_137[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (None, 6, 6, 160)            480       ['conv2d_138[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_138 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_138[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_15_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_138[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (None, 6, 6, 192)            576       ['conv2d_136[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (None, 6, 6, 192)            576       ['conv2d_139[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_136 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_136[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_139 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_139[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_16_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_136[0][0]',      \n",
      " ate)                                                                'activation_139[0][0]']      \n",
      "                                                                                                  \n",
      " block17_16_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_16_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_25 (Cus  (None, 6, 6, 1088)           0         ['block17_15_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_16_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_16_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_25[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_16_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (None, 6, 6, 128)            384       ['conv2d_141[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_141 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_141[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_141[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (None, 6, 6, 160)            480       ['conv2d_142[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_142 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_142[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_16_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_142[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (None, 6, 6, 192)            576       ['conv2d_140[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (None, 6, 6, 192)            576       ['conv2d_143[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_140 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_140[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_143 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_143[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_17_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_140[0][0]',      \n",
      " ate)                                                                'activation_143[0][0]']      \n",
      "                                                                                                  \n",
      " block17_17_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_17_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_26 (Cus  (None, 6, 6, 1088)           0         ['block17_16_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_17_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_17_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_26[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_17_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, 6, 6, 128)            384       ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_145 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_145[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_145[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, 6, 6, 160)            480       ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_146 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_146[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_17_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_146[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, 6, 6, 192)            576       ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, 6, 6, 192)            576       ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_144 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_144[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_147 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_147[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_18_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_144[0][0]',      \n",
      " ate)                                                                'activation_147[0][0]']      \n",
      "                                                                                                  \n",
      " block17_18_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_18_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_27 (Cus  (None, 6, 6, 1088)           0         ['block17_17_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_18_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_18_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_27[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_18_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, 6, 6, 128)            384       ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_149 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_149[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_149[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, 6, 6, 160)            480       ['conv2d_150[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_150 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_150[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_18_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_150[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, 6, 6, 192)            576       ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, 6, 6, 192)            576       ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_148 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_148[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_151 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_151[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_19_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_148[0][0]',      \n",
      " ate)                                                                'activation_151[0][0]']      \n",
      "                                                                                                  \n",
      " block17_19_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_19_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_28 (Cus  (None, 6, 6, 1088)           0         ['block17_18_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_19_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_19_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_28[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (None, 6, 6, 128)            139264    ['block17_19_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, 6, 6, 128)            384       ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_153 (Activation  (None, 6, 6, 128)            0         ['batch_normalization_153[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (None, 6, 6, 160)            143360    ['activation_153[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (None, 6, 6, 160)            480       ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_154 (Activation  (None, 6, 6, 160)            0         ['batch_normalization_154[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (None, 6, 6, 192)            208896    ['block17_19_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (None, 6, 6, 192)            215040    ['activation_154[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, 6, 6, 192)            576       ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (None, 6, 6, 192)            576       ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_152 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_152[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_155 (Activation  (None, 6, 6, 192)            0         ['batch_normalization_155[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block17_20_mixed (Concaten  (None, 6, 6, 384)            0         ['activation_152[0][0]',      \n",
      " ate)                                                                'activation_155[0][0]']      \n",
      "                                                                                                  \n",
      " block17_20_conv (Conv2D)    (None, 6, 6, 1088)           418880    ['block17_20_mixed[0][0]']    \n",
      "                                                                                                  \n",
      " custom_scale_layer_29 (Cus  (None, 6, 6, 1088)           0         ['block17_19_ac[0][0]',       \n",
      " tomScaleLayer)                                                      'block17_20_conv[0][0]']     \n",
      "                                                                                                  \n",
      " block17_20_ac (Activation)  (None, 6, 6, 1088)           0         ['custom_scale_layer_29[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)         (None, 6, 6, 256)            278528    ['block17_20_ac[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_160 (B  (None, 6, 6, 256)            768       ['conv2d_160[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_160 (Activation  (None, 6, 6, 256)            0         ['batch_normalization_160[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (None, 6, 6, 256)            278528    ['block17_20_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (None, 6, 6, 256)            278528    ['block17_20_ac[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)         (None, 6, 6, 288)            663552    ['activation_160[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (None, 6, 6, 256)            768       ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_158 (B  (None, 6, 6, 256)            768       ['conv2d_158[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_161 (B  (None, 6, 6, 288)            864       ['conv2d_161[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_156 (Activation  (None, 6, 6, 256)            0         ['batch_normalization_156[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_158 (Activation  (None, 6, 6, 256)            0         ['batch_normalization_158[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_161 (Activation  (None, 6, 6, 288)            0         ['batch_normalization_161[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (None, 2, 2, 384)            884736    ['activation_156[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (None, 2, 2, 288)            663552    ['activation_158[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)         (None, 2, 2, 320)            829440    ['activation_161[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_157 (B  (None, 2, 2, 384)            1152      ['conv2d_157[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_159 (B  (None, 2, 2, 288)            864       ['conv2d_159[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_162 (B  (None, 2, 2, 320)            960       ['conv2d_162[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_157 (Activation  (None, 2, 2, 384)            0         ['batch_normalization_157[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_159 (Activation  (None, 2, 2, 288)            0         ['batch_normalization_159[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_162 (Activation  (None, 2, 2, 320)            0         ['batch_normalization_162[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 2, 2, 1088)           0         ['block17_20_ac[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed_7a (Concatenate)      (None, 2, 2, 2080)           0         ['activation_157[0][0]',      \n",
      "                                                                     'activation_159[0][0]',      \n",
      "                                                                     'activation_162[0][0]',      \n",
      "                                                                     'max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)         (None, 2, 2, 192)            399360    ['mixed_7a[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_164 (B  (None, 2, 2, 192)            576       ['conv2d_164[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_164 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_164[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_164[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_165 (B  (None, 2, 2, 224)            672       ['conv2d_165[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_165 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_165[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)         (None, 2, 2, 192)            399360    ['mixed_7a[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_165[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_163 (B  (None, 2, 2, 192)            576       ['conv2d_163[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_166 (B  (None, 2, 2, 256)            768       ['conv2d_166[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_163 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_163[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_166 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_166[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_1_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_163[0][0]',      \n",
      " e)                                                                  'activation_166[0][0]']      \n",
      "                                                                                                  \n",
      " block8_1_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_1_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_30 (Cus  (None, 2, 2, 2080)           0         ['mixed_7a[0][0]',            \n",
      " tomScaleLayer)                                                      'block8_1_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_1_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_30[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_1_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_168 (B  (None, 2, 2, 192)            576       ['conv2d_168[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_168 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_168[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_168[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_169 (B  (None, 2, 2, 224)            672       ['conv2d_169[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_169 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_169[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_1_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_169[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_167 (B  (None, 2, 2, 192)            576       ['conv2d_167[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_170 (B  (None, 2, 2, 256)            768       ['conv2d_170[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_167 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_167[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_170 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_170[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_2_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_167[0][0]',      \n",
      " e)                                                                  'activation_170[0][0]']      \n",
      "                                                                                                  \n",
      " block8_2_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_2_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_31 (Cus  (None, 2, 2, 2080)           0         ['block8_1_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_2_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_2_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_31[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_2_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, 2, 2, 192)            576       ['conv2d_172[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_172 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_172[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_172[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, 2, 2, 224)            672       ['conv2d_173[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_173 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_173[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_2_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_173[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, 2, 2, 192)            576       ['conv2d_171[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_174 (B  (None, 2, 2, 256)            768       ['conv2d_174[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_171 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_171[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_174 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_174[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_3_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_171[0][0]',      \n",
      " e)                                                                  'activation_174[0][0]']      \n",
      "                                                                                                  \n",
      " block8_3_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_3_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_32 (Cus  (None, 2, 2, 2080)           0         ['block8_2_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_3_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_3_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_32[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_3_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_176 (B  (None, 2, 2, 192)            576       ['conv2d_176[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_176 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_176[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_176[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_177 (B  (None, 2, 2, 224)            672       ['conv2d_177[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_177 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_177[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_3_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_177[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_175 (B  (None, 2, 2, 192)            576       ['conv2d_175[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_178 (B  (None, 2, 2, 256)            768       ['conv2d_178[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_175 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_175[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_178 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_178[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_4_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_175[0][0]',      \n",
      " e)                                                                  'activation_178[0][0]']      \n",
      "                                                                                                  \n",
      " block8_4_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_4_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_33 (Cus  (None, 2, 2, 2080)           0         ['block8_3_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_4_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_4_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_33[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_4_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_180 (B  (None, 2, 2, 192)            576       ['conv2d_180[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_180 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_180[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_180[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_181 (B  (None, 2, 2, 224)            672       ['conv2d_181[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_181 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_181[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_4_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_181[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_179 (B  (None, 2, 2, 192)            576       ['conv2d_179[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_182 (B  (None, 2, 2, 256)            768       ['conv2d_182[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_179 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_179[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_182 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_182[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_5_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_179[0][0]',      \n",
      " e)                                                                  'activation_182[0][0]']      \n",
      "                                                                                                  \n",
      " block8_5_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_5_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_34 (Cus  (None, 2, 2, 2080)           0         ['block8_4_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_5_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_5_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_34[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_5_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_184 (B  (None, 2, 2, 192)            576       ['conv2d_184[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_184 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_184[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_185 (B  (None, 2, 2, 224)            672       ['conv2d_185[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_185 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_185[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_5_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_185[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_183 (B  (None, 2, 2, 192)            576       ['conv2d_183[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_186 (B  (None, 2, 2, 256)            768       ['conv2d_186[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_183 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_183[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_186 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_186[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_6_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_183[0][0]',      \n",
      " e)                                                                  'activation_186[0][0]']      \n",
      "                                                                                                  \n",
      " block8_6_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_6_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_35 (Cus  (None, 2, 2, 2080)           0         ['block8_5_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_6_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_6_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_35[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_6_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_188 (B  (None, 2, 2, 192)            576       ['conv2d_188[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_188 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_188[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_188[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_189 (B  (None, 2, 2, 224)            672       ['conv2d_189[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_189 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_189[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_6_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_189[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_187 (B  (None, 2, 2, 192)            576       ['conv2d_187[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_190 (B  (None, 2, 2, 256)            768       ['conv2d_190[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_187 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_187[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_190[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_7_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_187[0][0]',      \n",
      " e)                                                                  'activation_190[0][0]']      \n",
      "                                                                                                  \n",
      " block8_7_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_7_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_36 (Cus  (None, 2, 2, 2080)           0         ['block8_6_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_7_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_7_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_36[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_7_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (B  (None, 2, 2, 192)            576       ['conv2d_192[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_192[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_192[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_193 (B  (None, 2, 2, 224)            672       ['conv2d_193[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_193[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_7_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_193[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_191 (B  (None, 2, 2, 192)            576       ['conv2d_191[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_194 (B  (None, 2, 2, 256)            768       ['conv2d_194[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_191[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_194[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_8_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_191[0][0]',      \n",
      " e)                                                                  'activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " block8_8_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_8_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_37 (Cus  (None, 2, 2, 2080)           0         ['block8_7_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_8_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_8_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_37[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_8_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 2, 2, 192)            576       ['conv2d_196[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_196[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 2, 2, 224)            672       ['conv2d_197[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_197[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_8_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_197[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_195 (B  (None, 2, 2, 192)            576       ['conv2d_195[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 2, 2, 256)            768       ['conv2d_198[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_195[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_9_mixed (Concatenat  (None, 2, 2, 448)            0         ['activation_195[0][0]',      \n",
      " e)                                                                  'activation_198[0][0]']      \n",
      "                                                                                                  \n",
      " block8_9_conv (Conv2D)      (None, 2, 2, 2080)           933920    ['block8_9_mixed[0][0]']      \n",
      "                                                                                                  \n",
      " custom_scale_layer_38 (Cus  (None, 2, 2, 2080)           0         ['block8_8_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_9_conv[0][0]']       \n",
      "                                                                                                  \n",
      " block8_9_ac (Activation)    (None, 2, 2, 2080)           0         ['custom_scale_layer_38[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_9_ac[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 2, 2, 192)            576       ['conv2d_200[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_200 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)         (None, 2, 2, 224)            129024    ['activation_200[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 2, 2, 224)            672       ['conv2d_201[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_201 (Activation  (None, 2, 2, 224)            0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)         (None, 2, 2, 192)            399360    ['block8_9_ac[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)         (None, 2, 2, 256)            172032    ['activation_201[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 2, 2, 192)            576       ['conv2d_199[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 2, 2, 256)            768       ['conv2d_202[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 2, 2, 192)            0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_202 (Activation  (None, 2, 2, 256)            0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " block8_10_mixed (Concatena  (None, 2, 2, 448)            0         ['activation_199[0][0]',      \n",
      " te)                                                                 'activation_202[0][0]']      \n",
      "                                                                                                  \n",
      " block8_10_conv (Conv2D)     (None, 2, 2, 2080)           933920    ['block8_10_mixed[0][0]']     \n",
      "                                                                                                  \n",
      " custom_scale_layer_39 (Cus  (None, 2, 2, 2080)           0         ['block8_9_ac[0][0]',         \n",
      " tomScaleLayer)                                                      'block8_10_conv[0][0]']      \n",
      "                                                                                                  \n",
      " conv_7b (Conv2D)            (None, 2, 2, 1536)           3194880   ['custom_scale_layer_39[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv_7b_bn (BatchNormaliza  (None, 2, 2, 1536)           4608      ['conv_7b[0][0]']             \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " conv_7b_ac (Activation)     (None, 2, 2, 1536)           0         ['conv_7b_bn[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54336736 (207.28 MB)\n",
      "Trainable params: 54276192 (207.05 MB)\n",
      "Non-trainable params: 60544 (236.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)       (None, 63, 63, 32)           864       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " block1_conv1_bn (BatchNorm  (None, 63, 63, 32)           128       ['block1_conv1[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block1_conv1_act (Activati  (None, 63, 63, 32)           0         ['block1_conv1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)       (None, 61, 61, 64)           18432     ['block1_conv1_act[0][0]']    \n",
      "                                                                                                  \n",
      " block1_conv2_bn (BatchNorm  (None, 61, 61, 64)           256       ['block1_conv2[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block1_conv2_act (Activati  (None, 61, 61, 64)           0         ['block1_conv2_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block2_sepconv1 (Separable  (None, 61, 61, 128)          8768      ['block1_conv2_act[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block2_sepconv1_bn (BatchN  (None, 61, 61, 128)          512       ['block2_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2_sepconv2_act (Activ  (None, 61, 61, 128)          0         ['block2_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block2_sepconv2 (Separable  (None, 61, 61, 128)          17536     ['block2_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block2_sepconv2_bn (BatchN  (None, 61, 61, 128)          512       ['block2_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)         (None, 31, 31, 128)          8192      ['block1_conv2_act[0][0]']    \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)  (None, 31, 31, 128)          0         ['block2_sepconv2_bn[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 31, 31, 128)          512       ['conv2d_203[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 31, 31, 128)          0         ['block2_pool[0][0]',         \n",
      "                                                                     'batch_normalization_203[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block3_sepconv1_act (Activ  (None, 31, 31, 128)          0         ['add[0][0]']                 \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block3_sepconv1 (Separable  (None, 31, 31, 256)          33920     ['block3_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block3_sepconv1_bn (BatchN  (None, 31, 31, 256)          1024      ['block3_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3_sepconv2_act (Activ  (None, 31, 31, 256)          0         ['block3_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block3_sepconv2 (Separable  (None, 31, 31, 256)          67840     ['block3_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block3_sepconv2_bn (BatchN  (None, 31, 31, 256)          1024      ['block3_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)         (None, 16, 16, 256)          32768     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)          0         ['block3_sepconv2_bn[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 16, 16, 256)          1024      ['conv2d_204[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 16, 16, 256)          0         ['block3_pool[0][0]',         \n",
      "                                                                     'batch_normalization_204[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block4_sepconv1_act (Activ  (None, 16, 16, 256)          0         ['add_1[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block4_sepconv1 (Separable  (None, 16, 16, 728)          188672    ['block4_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block4_sepconv1_bn (BatchN  (None, 16, 16, 728)          2912      ['block4_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4_sepconv2_act (Activ  (None, 16, 16, 728)          0         ['block4_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block4_sepconv2 (Separable  (None, 16, 16, 728)          536536    ['block4_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block4_sepconv2_bn (BatchN  (None, 16, 16, 728)          2912      ['block4_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)         (None, 8, 8, 728)            186368    ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 728)            0         ['block4_sepconv2_bn[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 8, 8, 728)            2912      ['conv2d_205[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 8, 8, 728)            0         ['block4_pool[0][0]',         \n",
      "                                                                     'batch_normalization_205[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block5_sepconv1_act (Activ  (None, 8, 8, 728)            0         ['add_2[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block5_sepconv1 (Separable  (None, 8, 8, 728)            536536    ['block5_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block5_sepconv1_bn (BatchN  (None, 8, 8, 728)            2912      ['block5_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5_sepconv2_act (Activ  (None, 8, 8, 728)            0         ['block5_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block5_sepconv2 (Separable  (None, 8, 8, 728)            536536    ['block5_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block5_sepconv2_bn (BatchN  (None, 8, 8, 728)            2912      ['block5_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5_sepconv3_act (Activ  (None, 8, 8, 728)            0         ['block5_sepconv2_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block5_sepconv3 (Separable  (None, 8, 8, 728)            536536    ['block5_sepconv3_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block5_sepconv3_bn (BatchN  (None, 8, 8, 728)            2912      ['block5_sepconv3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 8, 8, 728)            0         ['block5_sepconv3_bn[0][0]',  \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " block6_sepconv1_act (Activ  (None, 8, 8, 728)            0         ['add_3[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block6_sepconv1 (Separable  (None, 8, 8, 728)            536536    ['block6_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block6_sepconv1_bn (BatchN  (None, 8, 8, 728)            2912      ['block6_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6_sepconv2_act (Activ  (None, 8, 8, 728)            0         ['block6_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block6_sepconv2 (Separable  (None, 8, 8, 728)            536536    ['block6_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block6_sepconv2_bn (BatchN  (None, 8, 8, 728)            2912      ['block6_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6_sepconv3_act (Activ  (None, 8, 8, 728)            0         ['block6_sepconv2_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block6_sepconv3 (Separable  (None, 8, 8, 728)            536536    ['block6_sepconv3_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block6_sepconv3_bn (BatchN  (None, 8, 8, 728)            2912      ['block6_sepconv3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 8, 8, 728)            0         ['block6_sepconv3_bn[0][0]',  \n",
      "                                                                     'add_3[0][0]']               \n",
      "                                                                                                  \n",
      " block7_sepconv1_act (Activ  (None, 8, 8, 728)            0         ['add_4[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block7_sepconv1 (Separable  (None, 8, 8, 728)            536536    ['block7_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block7_sepconv1_bn (BatchN  (None, 8, 8, 728)            2912      ['block7_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block7_sepconv2_act (Activ  (None, 8, 8, 728)            0         ['block7_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block7_sepconv2 (Separable  (None, 8, 8, 728)            536536    ['block7_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block7_sepconv2_bn (BatchN  (None, 8, 8, 728)            2912      ['block7_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block7_sepconv3_act (Activ  (None, 8, 8, 728)            0         ['block7_sepconv2_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block7_sepconv3 (Separable  (None, 8, 8, 728)            536536    ['block7_sepconv3_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block7_sepconv3_bn (BatchN  (None, 8, 8, 728)            2912      ['block7_sepconv3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 8, 8, 728)            0         ['block7_sepconv3_bn[0][0]',  \n",
      "                                                                     'add_4[0][0]']               \n",
      "                                                                                                  \n",
      " block8_sepconv1_act (Activ  (None, 8, 8, 728)            0         ['add_5[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block8_sepconv1 (Separable  (None, 8, 8, 728)            536536    ['block8_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block8_sepconv1_bn (BatchN  (None, 8, 8, 728)            2912      ['block8_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block8_sepconv2_act (Activ  (None, 8, 8, 728)            0         ['block8_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block8_sepconv2 (Separable  (None, 8, 8, 728)            536536    ['block8_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block8_sepconv2_bn (BatchN  (None, 8, 8, 728)            2912      ['block8_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block8_sepconv3_act (Activ  (None, 8, 8, 728)            0         ['block8_sepconv2_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block8_sepconv3 (Separable  (None, 8, 8, 728)            536536    ['block8_sepconv3_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block8_sepconv3_bn (BatchN  (None, 8, 8, 728)            2912      ['block8_sepconv3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 8, 8, 728)            0         ['block8_sepconv3_bn[0][0]',  \n",
      "                                                                     'add_5[0][0]']               \n",
      "                                                                                                  \n",
      " block9_sepconv1_act (Activ  (None, 8, 8, 728)            0         ['add_6[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block9_sepconv1 (Separable  (None, 8, 8, 728)            536536    ['block9_sepconv1_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block9_sepconv1_bn (BatchN  (None, 8, 8, 728)            2912      ['block9_sepconv1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block9_sepconv2_act (Activ  (None, 8, 8, 728)            0         ['block9_sepconv1_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block9_sepconv2 (Separable  (None, 8, 8, 728)            536536    ['block9_sepconv2_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block9_sepconv2_bn (BatchN  (None, 8, 8, 728)            2912      ['block9_sepconv2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block9_sepconv3_act (Activ  (None, 8, 8, 728)            0         ['block9_sepconv2_bn[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block9_sepconv3 (Separable  (None, 8, 8, 728)            536536    ['block9_sepconv3_act[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " block9_sepconv3_bn (BatchN  (None, 8, 8, 728)            2912      ['block9_sepconv3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 8, 8, 728)            0         ['block9_sepconv3_bn[0][0]',  \n",
      "                                                                     'add_6[0][0]']               \n",
      "                                                                                                  \n",
      " block10_sepconv1_act (Acti  (None, 8, 8, 728)            0         ['add_7[0][0]']               \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block10_sepconv1 (Separabl  (None, 8, 8, 728)            536536    ['block10_sepconv1_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block10_sepconv1_bn (Batch  (None, 8, 8, 728)            2912      ['block10_sepconv1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block10_sepconv2_act (Acti  (None, 8, 8, 728)            0         ['block10_sepconv1_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block10_sepconv2 (Separabl  (None, 8, 8, 728)            536536    ['block10_sepconv2_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block10_sepconv2_bn (Batch  (None, 8, 8, 728)            2912      ['block10_sepconv2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block10_sepconv3_act (Acti  (None, 8, 8, 728)            0         ['block10_sepconv2_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block10_sepconv3 (Separabl  (None, 8, 8, 728)            536536    ['block10_sepconv3_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block10_sepconv3_bn (Batch  (None, 8, 8, 728)            2912      ['block10_sepconv3[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 8, 8, 728)            0         ['block10_sepconv3_bn[0][0]', \n",
      "                                                                     'add_7[0][0]']               \n",
      "                                                                                                  \n",
      " block11_sepconv1_act (Acti  (None, 8, 8, 728)            0         ['add_8[0][0]']               \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block11_sepconv1 (Separabl  (None, 8, 8, 728)            536536    ['block11_sepconv1_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block11_sepconv1_bn (Batch  (None, 8, 8, 728)            2912      ['block11_sepconv1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block11_sepconv2_act (Acti  (None, 8, 8, 728)            0         ['block11_sepconv1_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block11_sepconv2 (Separabl  (None, 8, 8, 728)            536536    ['block11_sepconv2_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block11_sepconv2_bn (Batch  (None, 8, 8, 728)            2912      ['block11_sepconv2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block11_sepconv3_act (Acti  (None, 8, 8, 728)            0         ['block11_sepconv2_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block11_sepconv3 (Separabl  (None, 8, 8, 728)            536536    ['block11_sepconv3_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block11_sepconv3_bn (Batch  (None, 8, 8, 728)            2912      ['block11_sepconv3[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 8, 8, 728)            0         ['block11_sepconv3_bn[0][0]', \n",
      "                                                                     'add_8[0][0]']               \n",
      "                                                                                                  \n",
      " block12_sepconv1_act (Acti  (None, 8, 8, 728)            0         ['add_9[0][0]']               \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block12_sepconv1 (Separabl  (None, 8, 8, 728)            536536    ['block12_sepconv1_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block12_sepconv1_bn (Batch  (None, 8, 8, 728)            2912      ['block12_sepconv1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block12_sepconv2_act (Acti  (None, 8, 8, 728)            0         ['block12_sepconv1_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block12_sepconv2 (Separabl  (None, 8, 8, 728)            536536    ['block12_sepconv2_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block12_sepconv2_bn (Batch  (None, 8, 8, 728)            2912      ['block12_sepconv2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block12_sepconv3_act (Acti  (None, 8, 8, 728)            0         ['block12_sepconv2_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block12_sepconv3 (Separabl  (None, 8, 8, 728)            536536    ['block12_sepconv3_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block12_sepconv3_bn (Batch  (None, 8, 8, 728)            2912      ['block12_sepconv3[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 8, 8, 728)            0         ['block12_sepconv3_bn[0][0]', \n",
      "                                                                     'add_9[0][0]']               \n",
      "                                                                                                  \n",
      " block13_sepconv1_act (Acti  (None, 8, 8, 728)            0         ['add_10[0][0]']              \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block13_sepconv1 (Separabl  (None, 8, 8, 728)            536536    ['block13_sepconv1_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block13_sepconv1_bn (Batch  (None, 8, 8, 728)            2912      ['block13_sepconv1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block13_sepconv2_act (Acti  (None, 8, 8, 728)            0         ['block13_sepconv1_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block13_sepconv2 (Separabl  (None, 8, 8, 1024)           752024    ['block13_sepconv2_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block13_sepconv2_bn (Batch  (None, 8, 8, 1024)           4096      ['block13_sepconv2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)         (None, 4, 4, 1024)           745472    ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " block13_pool (MaxPooling2D  (None, 4, 4, 1024)           0         ['block13_sepconv2_bn[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 4, 4, 1024)           4096      ['conv2d_206[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 4, 4, 1024)           0         ['block13_pool[0][0]',        \n",
      "                                                                     'batch_normalization_206[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block14_sepconv1 (Separabl  (None, 4, 4, 1536)           1582080   ['add_11[0][0]']              \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block14_sepconv1_bn (Batch  (None, 4, 4, 1536)           6144      ['block14_sepconv1[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block14_sepconv1_act (Acti  (None, 4, 4, 1536)           0         ['block14_sepconv1_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " block14_sepconv2 (Separabl  (None, 4, 4, 2048)           3159552   ['block14_sepconv1_act[0][0]']\n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " block14_sepconv2_bn (Batch  (None, 4, 4, 2048)           8192      ['block14_sepconv2[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block14_sepconv2_act (Acti  (None, 4, 4, 2048)           0         ['block14_sepconv2_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20861480 (79.58 MB)\n",
      "Trainable params: 20806952 (79.37 MB)\n",
      "Non-trainable params: 54528 (213.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dic_base_models = {}\n",
    "\n",
    "dic_base_models[\"ResNet50V2\"] = keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"ResNet50V2\"].summary()\n",
    "\n",
    "dic_base_models[\"VGG16\"] = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    #input_shape= (128,128,3),\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"VGG16\"].summary()\n",
    "\n",
    "dic_base_models[\"InceptionResNetV2\"] = keras.applications.InceptionResNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"InceptionResNetV2\"].summary()\n",
    "\n",
    "dic_base_models[\"Xception\"] = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "dic_base_models[\"Xception\"].summary()\n",
    "\n",
    "\n",
    "\n",
    "for base_model in dic_base_models.values():\n",
    "\tbase_model.trainable = False\n",
    "\n",
    "#base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = models.Sequential([layers.RandomFlip(), \n",
    "                           layers.RandomRotation(factor=0.3), \n",
    "                           layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "                           layers.RandomTranslation(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1))\n",
    "                          ])\n",
    "\n",
    "preprocess = models.Sequential([augmentation,layers.BatchNormalization()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "modmetrics = [metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       metrics.AUC(name='AUROC'),\n",
    "                       metrics.Precision(name='precision'),\n",
    "                       metrics.Recall(name='recall'),\n",
    "\t\t\t\t\t   F1Score(average='macro', name=\"F1Macro\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#depois voltar a mudar o numero de epochs\n",
    "def compilation(model, metrics, optimizer=\"RMSprop\", learning_rate = dicParams[\"learning_rate\"], epochs = dicParams[\"epochs\"], verbose=1, loss=\"categorical_crossentropy\"):\n",
    "  if optimizer==\"RMSprop\":\n",
    "    optimizer=optimizers.RMSprop(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adam\":\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate)\n",
    "  elif optimizer==\"SGD\":\n",
    "    optimizer=optimizers.SGD(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Nadam\":\n",
    "    optimizer=optimizers.Nadam(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adadelta\":\n",
    "    optimizer=optimizers.Adadelta(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adagrad\":\n",
    "    optimizer=optimizers.Adagrad(learning_rate=learning_rate)\n",
    "  else:\n",
    "    print(\"Invalid optimizer\")\n",
    "    return None\n",
    "  \n",
    "  model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "  \n",
    "  history = model.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=verbose)\n",
    "\n",
    "  df_hist = pd.DataFrame.from_dict(history.history)\n",
    "  df_hist[\"Epoch\"] = np.arange(1, len(df_hist) + 1, 1)\n",
    "\n",
    "  #calculating the f1score for each epoch (train and validation)\n",
    "  df_hist['f1_calc'] = 2*(df_hist['precision']*df_hist['recall'])/(df_hist['precision'] + df_hist['recall'])\n",
    "  df_hist['val_f1_calc'] = 2*(df_hist['val_precision']*df_hist['val_recall'])/(df_hist['val_precision']+df_hist['val_recall'])\n",
    "  \n",
    "  return df_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_208 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_203 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_209 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_204 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_210 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_205 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_211 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_206 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_3 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dic_tranfs_models = {}\n",
    "\n",
    "for base_model_name in dic_base_models.keys():\n",
    "\t#inputs = keras.Input(shape=(128, 128, 3))\n",
    "\tinputs = keras.Input(shape=dicParams[\"input_shape\"])\n",
    "\n",
    "\tx = preprocess(inputs)\n",
    "\tx = base_model(x, training=False)\n",
    "\tx = keras.layers.BatchNormalization()(x)\n",
    "\tx = keras.layers.Activation(\"relu\")(x)\n",
    "\tx = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "\toutputs = keras.layers.Dense(dicParams[\"num_classes\"],activation=\"softmax\", \n",
    "\t\t\t\t\t\t\t\t\tkernel_initializer=keras.initializers.GlorotNormal(seed=dicParams[\"seed\"]))(x)\n",
    "\tmodelT = keras.Model(inputs, outputs)\n",
    "\n",
    "\tmodelT.summary()\n",
    "\tdic_tranfs_models[base_model_name] = modelT\n",
    "\n",
    "\t# dot_img_file = base_model_name + '.png'\n",
    "\t# keras.utils.plot_model(modelT, to_file=dot_img_file, show_shapes=True)\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  ResNet50V2 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "46/46 [==============================] - 162s 3s/step - loss: 6.3441 - accuracy: 0.0133 - AUROC: 0.5313 - precision: 0.0137 - recall: 0.0011 - F1Macro: 0.0083 - val_loss: 5.4837 - val_accuracy: 0.0194 - val_AUROC: 0.5539 - val_precision: 0.0690 - val_recall: 8.0743e-04 - val_F1Macro: 0.0060\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 160s 3s/step - loss: 5.8838 - accuracy: 0.0214 - AUROC: 0.5716 - precision: 0.0263 - recall: 0.0018 - F1Macro: 0.0114 - val_loss: 5.2845 - val_accuracy: 0.0190 - val_AUROC: 0.5842 - val_precision: 0.0312 - val_recall: 4.0371e-04 - val_F1Macro: 0.0075\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 160s 3s/step - loss: 5.7039 - accuracy: 0.0271 - AUROC: 0.5868 - precision: 0.0496 - recall: 0.0032 - F1Macro: 0.0149 - val_loss: 5.2104 - val_accuracy: 0.0262 - val_AUROC: 0.6044 - val_precision: 0.0488 - val_recall: 8.0743e-04 - val_F1Macro: 0.0111\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 157s 3s/step - loss: 5.5406 - accuracy: 0.0333 - AUROC: 0.6035 - precision: 0.0491 - recall: 0.0029 - F1Macro: 0.0180 - val_loss: 5.1555 - val_accuracy: 0.0371 - val_AUROC: 0.6186 - val_precision: 0.1268 - val_recall: 0.0036 - val_F1Macro: 0.0174\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 157s 3s/step - loss: 5.4125 - accuracy: 0.0369 - AUROC: 0.6185 - precision: 0.0695 - recall: 0.0040 - F1Macro: 0.0201 - val_loss: 5.1387 - val_accuracy: 0.0444 - val_AUROC: 0.6301 - val_precision: 0.1358 - val_recall: 0.0044 - val_F1Macro: 0.0185\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 225s 5s/step - loss: 4.8866 - accuracy: 0.0514 - AUROC: 0.6527 - precision: 0.1463 - recall: 0.0035 - F1Macro: 0.0237 - val_loss: 4.9571 - val_accuracy: 0.0597 - val_AUROC: 0.6642 - val_precision: 0.0758 - val_recall: 0.0020 - val_F1Macro: 0.0179\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 4.5024 - accuracy: 0.0682 - AUROC: 0.7002 - precision: 0.2121 - recall: 0.0012 - F1Macro: 0.0288 - val_loss: 4.6373 - val_accuracy: 0.0618 - val_AUROC: 0.6956 - val_precision: 0.2542 - val_recall: 0.0061 - val_F1Macro: 0.0180\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.3162 - accuracy: 0.0842 - AUROC: 0.7282 - precision: 0.4795 - recall: 0.0030 - F1Macro: 0.0373 - val_loss: 4.4873 - val_accuracy: 0.0747 - val_AUROC: 0.7137 - val_precision: 0.2333 - val_recall: 0.0028 - val_F1Macro: 0.0252\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 4.1956 - accuracy: 0.0967 - AUROC: 0.7478 - precision: 0.4571 - recall: 0.0028 - F1Macro: 0.0436 - val_loss: 4.3582 - val_accuracy: 0.0783 - val_AUROC: 0.7333 - val_precision: 0.3333 - val_recall: 0.0069 - val_F1Macro: 0.0329\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0955 - accuracy: 0.1116 - AUROC: 0.7668 - precision: 0.5536 - recall: 0.0054 - F1Macro: 0.0541 - val_loss: 4.3047 - val_accuracy: 0.0860 - val_AUROC: 0.7454 - val_precision: 0.2614 - val_recall: 0.0093 - val_F1Macro: 0.0343\n",
      "Model:  ResNet50V2 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 234s 5s/step - loss: 4.0527 - accuracy: 0.1083 - AUROC: 0.7702 - precision: 0.4264 - recall: 0.0081 - F1Macro: 0.0508 - val_loss: 4.2232 - val_accuracy: 0.0961 - val_AUROC: 0.7520 - val_precision: 0.4151 - val_recall: 0.0089 - val_F1Macro: 0.0421\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 221s 5s/step - loss: 4.0159 - accuracy: 0.1175 - AUROC: 0.7838 - precision: 0.5855 - recall: 0.0077 - F1Macro: 0.0571 - val_loss: 4.1901 - val_accuracy: 0.0997 - val_AUROC: 0.7566 - val_precision: 0.4000 - val_recall: 0.0065 - val_F1Macro: 0.0473\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.0078 - accuracy: 0.1188 - AUROC: 0.7819 - precision: 0.6129 - recall: 0.0082 - F1Macro: 0.0581 - val_loss: 4.1683 - val_accuracy: 0.1017 - val_AUROC: 0.7584 - val_precision: 0.4516 - val_recall: 0.0057 - val_F1Macro: 0.0500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.0027 - accuracy: 0.1231 - AUROC: 0.7835 - precision: 0.5969 - recall: 0.0067 - F1Macro: 0.0616 - val_loss: 4.1515 - val_accuracy: 0.1042 - val_AUROC: 0.7611 - val_precision: 0.4444 - val_recall: 0.0048 - val_F1Macro: 0.0524\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9951 - accuracy: 0.1245 - AUROC: 0.7851 - precision: 0.6296 - recall: 0.0074 - F1Macro: 0.0629 - val_loss: 4.1406 - val_accuracy: 0.1058 - val_AUROC: 0.7631 - val_precision: 0.4800 - val_recall: 0.0048 - val_F1Macro: 0.0524\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 3.9849 - accuracy: 0.1225 - AUROC: 0.7835 - precision: 0.5844 - recall: 0.0064 - F1Macro: 0.0634 - val_loss: 4.1298 - val_accuracy: 0.1070 - val_AUROC: 0.7644 - val_precision: 0.4231 - val_recall: 0.0044 - val_F1Macro: 0.0525\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.9654 - accuracy: 0.1250 - AUROC: 0.7897 - precision: 0.6260 - recall: 0.0071 - F1Macro: 0.0644 - val_loss: 4.1225 - val_accuracy: 0.1082 - val_AUROC: 0.7661 - val_precision: 0.4231 - val_recall: 0.0044 - val_F1Macro: 0.0529\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.9613 - accuracy: 0.1237 - AUROC: 0.7898 - precision: 0.6621 - recall: 0.0083 - F1Macro: 0.0619 - val_loss: 4.1137 - val_accuracy: 0.1078 - val_AUROC: 0.7677 - val_precision: 0.5000 - val_recall: 0.0052 - val_F1Macro: 0.0528\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9453 - accuracy: 0.1308 - AUROC: 0.7925 - precision: 0.6667 - recall: 0.0081 - F1Macro: 0.0688 - val_loss: 4.1060 - val_accuracy: 0.1078 - val_AUROC: 0.7682 - val_precision: 0.5000 - val_recall: 0.0048 - val_F1Macro: 0.0522\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9372 - accuracy: 0.1310 - AUROC: 0.7942 - precision: 0.6618 - recall: 0.0078 - F1Macro: 0.0667 - val_loss: 4.0987 - val_accuracy: 0.1082 - val_AUROC: 0.7693 - val_precision: 0.5000 - val_recall: 0.0052 - val_F1Macro: 0.0527\n",
      "Model:  VGG16 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 4.6239 - accuracy: 0.0711 - AUROC: 0.6977 - precision: 0.2759 - recall: 0.0011 - F1Macro: 0.0336 - val_loss: 4.5051 - val_accuracy: 0.0513 - val_AUROC: 0.7048 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_F1Macro: 0.0138\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.2011 - accuracy: 0.0970 - AUROC: 0.7471 - precision: 0.4286 - recall: 7.7882e-04 - F1Macro: 0.0377 - val_loss: 4.3861 - val_accuracy: 0.0593 - val_AUROC: 0.7279 - val_precision: 0.2105 - val_recall: 0.0016 - val_F1Macro: 0.0128\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0907 - accuracy: 0.1112 - AUROC: 0.7673 - precision: 0.5000 - recall: 0.0023 - F1Macro: 0.0473 - val_loss: 4.2417 - val_accuracy: 0.0791 - val_AUROC: 0.7466 - val_precision: 0.6000 - val_recall: 0.0024 - val_F1Macro: 0.0263\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0087 - accuracy: 0.1229 - AUROC: 0.7821 - precision: 0.6848 - recall: 0.0055 - F1Macro: 0.0571 - val_loss: 4.1169 - val_accuracy: 0.0989 - val_AUROC: 0.7673 - val_precision: 0.3636 - val_recall: 0.0032 - val_F1Macro: 0.0454\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.9156 - accuracy: 0.1320 - AUROC: 0.7992 - precision: 0.7124 - recall: 0.0094 - F1Macro: 0.0623 - val_loss: 4.0768 - val_accuracy: 0.1066 - val_AUROC: 0.7737 - val_precision: 0.6000 - val_recall: 0.0061 - val_F1Macro: 0.0519\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.8487 - accuracy: 0.1339 - AUROC: 0.8011 - precision: 0.7037 - recall: 0.0122 - F1Macro: 0.0701 - val_loss: 4.0206 - val_accuracy: 0.1046 - val_AUROC: 0.7815 - val_precision: 0.5135 - val_recall: 0.0077 - val_F1Macro: 0.0553\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.7884 - accuracy: 0.1494 - AUROC: 0.8166 - precision: 0.7245 - recall: 0.0166 - F1Macro: 0.0815 - val_loss: 3.9608 - val_accuracy: 0.1219 - val_AUROC: 0.7902 - val_precision: 0.5417 - val_recall: 0.0105 - val_F1Macro: 0.0601\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.7173 - accuracy: 0.1586 - AUROC: 0.8269 - precision: 0.7301 - recall: 0.0206 - F1Macro: 0.0907 - val_loss: 3.8991 - val_accuracy: 0.1272 - val_AUROC: 0.7991 - val_precision: 0.5556 - val_recall: 0.0121 - val_F1Macro: 0.0680\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6569 - accuracy: 0.1688 - AUROC: 0.8359 - precision: 0.7429 - recall: 0.0250 - F1Macro: 0.1006 - val_loss: 3.8880 - val_accuracy: 0.1304 - val_AUROC: 0.8017 - val_precision: 0.6271 - val_recall: 0.0149 - val_F1Macro: 0.0743\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6187 - accuracy: 0.1712 - AUROC: 0.8403 - precision: 0.7143 - recall: 0.0273 - F1Macro: 0.1027 - val_loss: 3.8233 - val_accuracy: 0.1457 - val_AUROC: 0.8085 - val_precision: 0.5556 - val_recall: 0.0161 - val_F1Macro: 0.0784\n",
      "Model:  VGG16 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 231s 5s/step - loss: 3.5809 - accuracy: 0.1666 - AUROC: 0.8384 - precision: 0.7119 - recall: 0.0276 - F1Macro: 0.0981 - val_loss: 3.8000 - val_accuracy: 0.1486 - val_AUROC: 0.8120 - val_precision: 0.6301 - val_recall: 0.0186 - val_F1Macro: 0.0848\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 221s 5s/step - loss: 3.5665 - accuracy: 0.1802 - AUROC: 0.8457 - precision: 0.7702 - recall: 0.0313 - F1Macro: 0.1122 - val_loss: 3.7888 - val_accuracy: 0.1494 - val_AUROC: 0.8143 - val_precision: 0.6389 - val_recall: 0.0186 - val_F1Macro: 0.0902\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 220s 5s/step - loss: 3.5479 - accuracy: 0.1827 - AUROC: 0.8489 - precision: 0.7596 - recall: 0.0292 - F1Macro: 0.1133 - val_loss: 3.7803 - val_accuracy: 0.1522 - val_AUROC: 0.8152 - val_precision: 0.6486 - val_recall: 0.0194 - val_F1Macro: 0.0931\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5328 - accuracy: 0.1854 - AUROC: 0.8510 - precision: 0.7445 - recall: 0.0295 - F1Macro: 0.1154 - val_loss: 3.7763 - val_accuracy: 0.1518 - val_AUROC: 0.8167 - val_precision: 0.6486 - val_recall: 0.0194 - val_F1Macro: 0.0923\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.5397 - accuracy: 0.1826 - AUROC: 0.8508 - precision: 0.7560 - recall: 0.0300 - F1Macro: 0.1146 - val_loss: 3.7726 - val_accuracy: 0.1518 - val_AUROC: 0.8173 - val_precision: 0.6753 - val_recall: 0.0210 - val_F1Macro: 0.0925\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 229s 5s/step - loss: 3.5266 - accuracy: 0.1780 - AUROC: 0.8455 - precision: 0.7522 - recall: 0.0305 - F1Macro: 0.1129 - val_loss: 3.7690 - val_accuracy: 0.1534 - val_AUROC: 0.8181 - val_precision: 0.6543 - val_recall: 0.0214 - val_F1Macro: 0.0932\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5135 - accuracy: 0.1905 - AUROC: 0.8524 - precision: 0.7728 - recall: 0.0330 - F1Macro: 0.1245 - val_loss: 3.7646 - val_accuracy: 0.1526 - val_AUROC: 0.8182 - val_precision: 0.6667 - val_recall: 0.0218 - val_F1Macro: 0.0928\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5202 - accuracy: 0.1893 - AUROC: 0.8524 - precision: 0.7233 - recall: 0.0317 - F1Macro: 0.1179 - val_loss: 3.7630 - val_accuracy: 0.1522 - val_AUROC: 0.8178 - val_precision: 0.6667 - val_recall: 0.0210 - val_F1Macro: 0.0933\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5128 - accuracy: 0.1924 - AUROC: 0.8520 - precision: 0.7575 - recall: 0.0327 - F1Macro: 0.1231 - val_loss: 3.7605 - val_accuracy: 0.1534 - val_AUROC: 0.8179 - val_precision: 0.6753 - val_recall: 0.0210 - val_F1Macro: 0.0938\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5121 - accuracy: 0.1861 - AUROC: 0.8526 - precision: 0.7371 - recall: 0.0308 - F1Macro: 0.1212 - val_loss: 3.7580 - val_accuracy: 0.1562 - val_AUROC: 0.8181 - val_precision: 0.6842 - val_recall: 0.0210 - val_F1Macro: 0.0953\n",
      "Model:  InceptionResNetV2 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.9758 - accuracy: 0.1453 - AUROC: 0.7902 - precision: 0.6516 - recall: 0.0164 - F1Macro: 0.0865 - val_loss: 4.1610 - val_accuracy: 0.1005 - val_AUROC: 0.7680 - val_precision: 0.4545 - val_recall: 0.0081 - val_F1Macro: 0.0448\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6582 - accuracy: 0.1709 - AUROC: 0.8343 - precision: 0.7160 - recall: 0.0209 - F1Macro: 0.1020 - val_loss: 3.9566 - val_accuracy: 0.1199 - val_AUROC: 0.7939 - val_precision: 0.4545 - val_recall: 0.0141 - val_F1Macro: 0.0562\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.5823 - accuracy: 0.1792 - AUROC: 0.8440 - precision: 0.7380 - recall: 0.0266 - F1Macro: 0.1081 - val_loss: 3.9126 - val_accuracy: 0.1199 - val_AUROC: 0.8032 - val_precision: 0.3662 - val_recall: 0.0105 - val_F1Macro: 0.0715\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.5258 - accuracy: 0.1879 - AUROC: 0.8512 - precision: 0.7370 - recall: 0.0293 - F1Macro: 0.1203 - val_loss: 3.7986 - val_accuracy: 0.1405 - val_AUROC: 0.8147 - val_precision: 0.5930 - val_recall: 0.0206 - val_F1Macro: 0.0849\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.4687 - accuracy: 0.1965 - AUROC: 0.8583 - precision: 0.7437 - recall: 0.0357 - F1Macro: 0.1295 - val_loss: 3.7836 - val_accuracy: 0.1453 - val_AUROC: 0.8141 - val_precision: 0.4804 - val_recall: 0.0198 - val_F1Macro: 0.0878\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.4276 - accuracy: 0.1924 - AUROC: 0.8530 - precision: 0.7193 - recall: 0.0338 - F1Macro: 0.1310 - val_loss: 3.7196 - val_accuracy: 0.1534 - val_AUROC: 0.8229 - val_precision: 0.5385 - val_recall: 0.0198 - val_F1Macro: 0.1057\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.3609 - accuracy: 0.2166 - AUROC: 0.8675 - precision: 0.7692 - recall: 0.0424 - F1Macro: 0.1491 - val_loss: 3.7004 - val_accuracy: 0.1607 - val_AUROC: 0.8221 - val_precision: 0.5536 - val_recall: 0.0250 - val_F1Macro: 0.1148\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.3335 - accuracy: 0.2210 - AUROC: 0.8712 - precision: 0.7625 - recall: 0.0461 - F1Macro: 0.1593 - val_loss: 3.6520 - val_accuracy: 0.1752 - val_AUROC: 0.8285 - val_precision: 0.5099 - val_recall: 0.0311 - val_F1Macro: 0.1265\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.2963 - accuracy: 0.2269 - AUROC: 0.8740 - precision: 0.7662 - recall: 0.0491 - F1Macro: 0.1658 - val_loss: 3.7067 - val_accuracy: 0.1595 - val_AUROC: 0.8202 - val_precision: 0.5260 - val_recall: 0.0408 - val_F1Macro: 0.1138\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2518 - accuracy: 0.2312 - AUROC: 0.8782 - precision: 0.7726 - recall: 0.0547 - F1Macro: 0.1701 - val_loss: 3.6658 - val_accuracy: 0.1651 - val_AUROC: 0.8254 - val_precision: 0.6727 - val_recall: 0.0299 - val_F1Macro: 0.1259\n",
      "Model:  InceptionResNetV2 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 3.2242 - accuracy: 0.2248 - AUROC: 0.8708 - precision: 0.7669 - recall: 0.0485 - F1Macro: 0.1658 - val_loss: 3.6096 - val_accuracy: 0.1768 - val_AUROC: 0.8321 - val_precision: 0.6694 - val_recall: 0.0335 - val_F1Macro: 0.1334\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2229 - accuracy: 0.2359 - AUROC: 0.8812 - precision: 0.7760 - recall: 0.0543 - F1Macro: 0.1742 - val_loss: 3.5916 - val_accuracy: 0.1772 - val_AUROC: 0.8342 - val_precision: 0.6640 - val_recall: 0.0335 - val_F1Macro: 0.1317\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.2041 - accuracy: 0.2421 - AUROC: 0.8830 - precision: 0.7808 - recall: 0.0555 - F1Macro: 0.1815 - val_loss: 3.5809 - val_accuracy: 0.1825 - val_AUROC: 0.8358 - val_precision: 0.6842 - val_recall: 0.0367 - val_F1Macro: 0.1350\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1961 - accuracy: 0.2443 - AUROC: 0.8831 - precision: 0.7657 - recall: 0.0560 - F1Macro: 0.1787 - val_loss: 3.5755 - val_accuracy: 0.1853 - val_AUROC: 0.8355 - val_precision: 0.6692 - val_recall: 0.0359 - val_F1Macro: 0.1375\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1971 - accuracy: 0.2403 - AUROC: 0.8835 - precision: 0.7675 - recall: 0.0569 - F1Macro: 0.1776 - val_loss: 3.5726 - val_accuracy: 0.1849 - val_AUROC: 0.8353 - val_precision: 0.6765 - val_recall: 0.0371 - val_F1Macro: 0.1360\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 231s 5s/step - loss: 3.1836 - accuracy: 0.2330 - AUROC: 0.8758 - precision: 0.7754 - recall: 0.0549 - F1Macro: 0.1741 - val_loss: 3.5723 - val_accuracy: 0.1881 - val_AUROC: 0.8349 - val_precision: 0.6571 - val_recall: 0.0371 - val_F1Macro: 0.1373\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1835 - accuracy: 0.2449 - AUROC: 0.8843 - precision: 0.7884 - recall: 0.0577 - F1Macro: 0.1838 - val_loss: 3.5661 - val_accuracy: 0.1910 - val_AUROC: 0.8359 - val_precision: 0.6486 - val_recall: 0.0388 - val_F1Macro: 0.1406\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.1810 - accuracy: 0.2494 - AUROC: 0.8840 - precision: 0.7732 - recall: 0.0584 - F1Macro: 0.1865 - val_loss: 3.5620 - val_accuracy: 0.1910 - val_AUROC: 0.8371 - val_precision: 0.6599 - val_recall: 0.0392 - val_F1Macro: 0.1399\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1625 - accuracy: 0.2534 - AUROC: 0.8856 - precision: 0.7905 - recall: 0.0591 - F1Macro: 0.1915 - val_loss: 3.5630 - val_accuracy: 0.1897 - val_AUROC: 0.8366 - val_precision: 0.6327 - val_recall: 0.0375 - val_F1Macro: 0.1391\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1683 - accuracy: 0.2465 - AUROC: 0.8855 - precision: 0.8018 - recall: 0.0616 - F1Macro: 0.1817 - val_loss: 3.5615 - val_accuracy: 0.1897 - val_AUROC: 0.8366 - val_precision: 0.6434 - val_recall: 0.0371 - val_F1Macro: 0.1392\n",
      "Model:  Xception , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 225s 5s/step - loss: 3.5569 - accuracy: 0.2057 - AUROC: 0.8375 - precision: 0.6991 - recall: 0.0430 - F1Macro: 0.1423 - val_loss: 3.9325 - val_accuracy: 0.1239 - val_AUROC: 0.8016 - val_precision: 0.4672 - val_recall: 0.0230 - val_F1Macro: 0.0638\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2821 - accuracy: 0.2367 - AUROC: 0.8742 - precision: 0.7770 - recall: 0.0504 - F1Macro: 0.1695 - val_loss: 3.7921 - val_accuracy: 0.1397 - val_AUROC: 0.8177 - val_precision: 0.3923 - val_recall: 0.0206 - val_F1Macro: 0.0878\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.2449 - accuracy: 0.2381 - AUROC: 0.8783 - precision: 0.7638 - recall: 0.0537 - F1Macro: 0.1764 - val_loss: 3.6789 - val_accuracy: 0.1631 - val_AUROC: 0.8246 - val_precision: 0.4815 - val_recall: 0.0262 - val_F1Macro: 0.1116\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1984 - accuracy: 0.2493 - AUROC: 0.8831 - precision: 0.7609 - recall: 0.0573 - F1Macro: 0.1883 - val_loss: 3.6079 - val_accuracy: 0.1861 - val_AUROC: 0.8306 - val_precision: 0.6210 - val_recall: 0.0311 - val_F1Macro: 0.1360\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1589 - accuracy: 0.2542 - AUROC: 0.8852 - precision: 0.7809 - recall: 0.0617 - F1Macro: 0.1933 - val_loss: 3.5812 - val_accuracy: 0.1825 - val_AUROC: 0.8358 - val_precision: 0.6098 - val_recall: 0.0303 - val_F1Macro: 0.1387\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.1160 - accuracy: 0.2461 - AUROC: 0.8799 - precision: 0.7486 - recall: 0.0590 - F1Macro: 0.1932 - val_loss: 3.5624 - val_accuracy: 0.1893 - val_AUROC: 0.8333 - val_precision: 0.6800 - val_recall: 0.0480 - val_F1Macro: 0.1401\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0937 - accuracy: 0.2675 - AUROC: 0.8915 - precision: 0.7536 - recall: 0.0678 - F1Macro: 0.2088 - val_loss: 3.5134 - val_accuracy: 0.1922 - val_AUROC: 0.8425 - val_precision: 0.6146 - val_recall: 0.0476 - val_F1Macro: 0.1419\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0425 - accuracy: 0.2721 - AUROC: 0.8947 - precision: 0.7765 - recall: 0.0755 - F1Macro: 0.2144 - val_loss: 3.5582 - val_accuracy: 0.1974 - val_AUROC: 0.8364 - val_precision: 0.6242 - val_recall: 0.0416 - val_F1Macro: 0.1559\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0300 - accuracy: 0.2714 - AUROC: 0.8968 - precision: 0.7823 - recall: 0.0749 - F1Macro: 0.2137 - val_loss: 3.4978 - val_accuracy: 0.1938 - val_AUROC: 0.8437 - val_precision: 0.6198 - val_recall: 0.0480 - val_F1Macro: 0.1437\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9955 - accuracy: 0.2819 - AUROC: 0.8989 - precision: 0.7824 - recall: 0.0794 - F1Macro: 0.2267 - val_loss: 3.4541 - val_accuracy: 0.2047 - val_AUROC: 0.8470 - val_precision: 0.6425 - val_recall: 0.0573 - val_F1Macro: 0.1601\n",
      "Model:  Xception , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 2.9630 - accuracy: 0.2741 - AUROC: 0.8932 - precision: 0.7676 - recall: 0.0793 - F1Macro: 0.2262 - val_loss: 3.4522 - val_accuracy: 0.2107 - val_AUROC: 0.8463 - val_precision: 0.6250 - val_recall: 0.0545 - val_F1Macro: 0.1645\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9407 - accuracy: 0.2892 - AUROC: 0.9039 - precision: 0.7982 - recall: 0.0859 - F1Macro: 0.2368 - val_loss: 3.4550 - val_accuracy: 0.2111 - val_AUROC: 0.8453 - val_precision: 0.6333 - val_recall: 0.0537 - val_F1Macro: 0.1649\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9348 - accuracy: 0.2961 - AUROC: 0.9038 - precision: 0.7875 - recall: 0.0853 - F1Macro: 0.2398 - val_loss: 3.4569 - val_accuracy: 0.2132 - val_AUROC: 0.8455 - val_precision: 0.6291 - val_recall: 0.0541 - val_F1Macro: 0.1657\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9233 - accuracy: 0.3006 - AUROC: 0.9043 - precision: 0.7865 - recall: 0.0854 - F1Macro: 0.2432 - val_loss: 3.4557 - val_accuracy: 0.2111 - val_AUROC: 0.8457 - val_precision: 0.6456 - val_recall: 0.0537 - val_F1Macro: 0.1635\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9274 - accuracy: 0.2953 - AUROC: 0.9041 - precision: 0.8000 - recall: 0.0890 - F1Macro: 0.2378 - val_loss: 3.4555 - val_accuracy: 0.2111 - val_AUROC: 0.8459 - val_precision: 0.6540 - val_recall: 0.0557 - val_F1Macro: 0.1636\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 2.9157 - accuracy: 0.2838 - AUROC: 0.8939 - precision: 0.7747 - recall: 0.0828 - F1Macro: 0.2295 - val_loss: 3.4523 - val_accuracy: 0.2091 - val_AUROC: 0.8465 - val_precision: 0.6462 - val_recall: 0.0553 - val_F1Macro: 0.1610\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9191 - accuracy: 0.2941 - AUROC: 0.9062 - precision: 0.7780 - recall: 0.0895 - F1Macro: 0.2400 - val_loss: 3.4523 - val_accuracy: 0.2099 - val_AUROC: 0.8462 - val_precision: 0.6465 - val_recall: 0.0561 - val_F1Macro: 0.1620\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9165 - accuracy: 0.2935 - AUROC: 0.9052 - precision: 0.8075 - recall: 0.0897 - F1Macro: 0.2388 - val_loss: 3.4456 - val_accuracy: 0.2099 - val_AUROC: 0.8462 - val_precision: 0.6419 - val_recall: 0.0557 - val_F1Macro: 0.1607\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9130 - accuracy: 0.2988 - AUROC: 0.9051 - precision: 0.7913 - recall: 0.0909 - F1Macro: 0.2431 - val_loss: 3.4469 - val_accuracy: 0.2128 - val_AUROC: 0.8458 - val_precision: 0.6393 - val_recall: 0.0565 - val_F1Macro: 0.1637\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9040 - accuracy: 0.3059 - AUROC: 0.9043 - precision: 0.8053 - recall: 0.0898 - F1Macro: 0.2491 - val_loss: 3.4457 - val_accuracy: 0.2156 - val_AUROC: 0.8458 - val_precision: 0.6425 - val_recall: 0.0573 - val_F1Macro: 0.1662\n"
     ]
    }
   ],
   "source": [
    "tfs = {}\n",
    "epochsfreeze = 5\n",
    "epochsunfreeze = 5\n",
    "\n",
    "for modelT_name in dic_tranfs_models.keys():\n",
    "\tmodelT = dic_tranfs_models[modelT_name]\n",
    "\n",
    "\t# lstoptimizers = [\"SGD\", \"Adam\", \"Nadam\", \"Adadelta\", \"Adagrad\", \"RMSprop\"]\n",
    "\tlstoptimizers = [\"Adagrad\", \"Adadelta\"]\n",
    "\tfor opt in lstoptimizers:\n",
    "\t\tprint(\"Model: \", modelT_name, \", optimizer:\", opt, \"learning_rate:\", dicParams[\"learning_rate\"], \"epochs:\", epochsfreeze)\n",
    "\t\t\n",
    "\t\tres = compilation(modelT, metrics = modmetrics, optimizer=opt, learning_rate = dicParams[\"learning_rate\"], epochs=epochsfreeze)\n",
    "\t\ttfs[modelT_name + \" : \" + opt] = res\n",
    "\n",
    "\t\t# Unfreeze all layers\n",
    "\t\tmodelT.trainable = True\n",
    "\t\t#modelT.summary()\n",
    "\t\t# dot_img_file = modelT_name + '_unfreeze.png'\n",
    "\t\t# keras.utils.plot_model(modelT, to_file=dot_img_file, show_shapes=True)\n",
    "\t\tres2 = compilation(modelT, metrics = modmetrics, optimizer=opt, learning_rate = dicParams[\"learning_rate\"], epochs=epochsunfreeze)\n",
    "\t\ttfs[modelT_name + \" : \" + opt + \" : Unfrozen\"] = res2\n",
    "\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model : Optimizer:  ResNet50V2 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  6.344058  0.013326  0.531298   0.013684  0.001125  0.008345  5.483694   \n",
      "1  5.883828  0.021374  0.571639   0.026283  0.001817  0.011369  5.284451   \n",
      "2  5.703894  0.027085  0.586788   0.049598  0.003202  0.014883  5.210447   \n",
      "3  5.540602  0.033316  0.603510   0.049133  0.002942  0.018042  5.155463   \n",
      "4  5.412502  0.036864  0.618502   0.069486  0.003981  0.020078  5.138659   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.019378   0.553916       0.068966    0.000807     0.005968      1   \n",
      "1      0.018975   0.584177       0.031250    0.000404     0.007472      2   \n",
      "2      0.026241   0.604449       0.048780    0.000807     0.011133      3   \n",
      "3      0.037142   0.618578       0.126761    0.003633     0.017423      4   \n",
      "4      0.044409   0.630097       0.135802    0.004441     0.018504      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.002079     0.001596  \n",
      "1  0.003399     0.000797  \n",
      "2  0.006015     0.001589  \n",
      "3  0.005552     0.007064  \n",
      "4  0.007530     0.008600  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.886632  0.051379  0.652731   0.146269  0.003492  0.023730  4.957102   \n",
      "1  4.502393  0.068190  0.700245   0.212121  0.001211  0.028798  4.637305   \n",
      "2  4.316155  0.084199  0.728198   0.479452  0.003029  0.037303  4.487314   \n",
      "3  4.195566  0.096746  0.747843   0.457143  0.002769  0.043649  4.358168   \n",
      "4  4.095477  0.111630  0.766792   0.553571  0.005365  0.054092  4.304657   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.059750   0.664234       0.075758    0.002019     0.017879      1   \n",
      "1      0.061768   0.695587       0.254237    0.006056     0.017976      2   \n",
      "2      0.074687   0.713728       0.233333    0.002826     0.025186      3   \n",
      "3      0.078321   0.733292       0.333333    0.006863     0.032913      4   \n",
      "4      0.085991   0.745443       0.261364    0.009285     0.034304      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.006821     0.003932  \n",
      "1  0.002409     0.011830  \n",
      "2  0.006019     0.005584  \n",
      "3  0.005505     0.013449  \n",
      "4  0.010627     0.017934  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.052679  0.108316  0.770154   0.426415  0.008052  0.050783  4.223194   \n",
      "1  4.015875  0.117515  0.783760   0.585526  0.007702  0.057057  4.190098   \n",
      "2  4.007836  0.118813  0.781933   0.612903  0.008221  0.058135  4.168252   \n",
      "3  4.002694  0.123053  0.783487   0.596899  0.006663  0.061570  4.151511   \n",
      "4  3.995120  0.124524  0.785067   0.629630  0.007355  0.062869  4.140556   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.096084   0.751998       0.415094    0.008882     0.042084      1   \n",
      "1      0.099717   0.756644       0.400000    0.006459     0.047326      2   \n",
      "2      0.101736   0.758413       0.451613    0.005652     0.050046      3   \n",
      "3      0.104158   0.761095       0.444444    0.004845     0.052387      4   \n",
      "4      0.105773   0.763117       0.480000    0.004845     0.052364      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.015806     0.017391  \n",
      "1  0.015203     0.012714  \n",
      "2  0.016224     0.011164  \n",
      "3  0.013179     0.009585  \n",
      "4  0.014541     0.009592  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.984897  0.122497  0.783546   0.584416  0.006413  0.063436  4.129817   \n",
      "1  3.965362  0.124957  0.789720   0.625954  0.007096  0.064430  4.122509   \n",
      "2  3.961303  0.123745  0.789806   0.662069  0.008307  0.061945  4.113707   \n",
      "3  3.945269  0.130841  0.792501   0.666667  0.008134  0.068797  4.105951   \n",
      "4  3.937173  0.131014  0.794172   0.661765  0.007788  0.066740  4.098728   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.106984   0.764421       0.423077    0.004441     0.052532      1   \n",
      "1      0.108195   0.766088       0.423077    0.004441     0.052895      2   \n",
      "2      0.107792   0.767724       0.500000    0.005248     0.052765      3   \n",
      "3      0.107792   0.768160       0.500000    0.004845     0.052247      4   \n",
      "4      0.108195   0.769259       0.500000    0.005248     0.052668      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.012688     0.008789  \n",
      "1  0.014033     0.008789  \n",
      "2  0.016409     0.010388  \n",
      "3  0.016072     0.009596  \n",
      "4  0.015395     0.010388  \n",
      "-- Model : Optimizer:  VGG16 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.623932  0.071118  0.697739   0.275862  0.001140  0.033573  4.505054   \n",
      "1  4.201077  0.097006  0.747111   0.428571  0.000779  0.037663  4.386085   \n",
      "2  4.090651  0.111198  0.767319   0.500000  0.002336  0.047256  4.241683   \n",
      "3  4.008705  0.122880  0.782125   0.684783  0.005452  0.057070  4.116879   \n",
      "4  3.915635  0.131966  0.799221   0.712418  0.009432  0.062295  4.076803   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.051272   0.704776       0.000000    0.000000     0.013758      1   \n",
      "1      0.059346   0.727923       0.210526    0.001615     0.012754      2   \n",
      "2      0.079128   0.746564       0.600000    0.002422     0.026296      3   \n",
      "3      0.098910   0.767303       0.363636    0.003230     0.045365      4   \n",
      "4      0.106581   0.773653       0.600000    0.006056     0.051932      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.002271          NaN  \n",
      "1  0.001555     0.003205  \n",
      "2  0.004651     0.004825  \n",
      "3  0.010817     0.006403  \n",
      "4  0.018618     0.011990  \n",
      "-- Model : Optimizer:  VGG16 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.848671  0.133899  0.801087   0.703704  0.012186  0.070099  4.020621   \n",
      "1  3.788385  0.149446  0.816641   0.724528  0.016615  0.081484  3.960827   \n",
      "2  3.717280  0.158619  0.826878   0.730061  0.020595  0.090698  3.899065   \n",
      "3  3.656883  0.168830  0.835863   0.742931  0.025009  0.100585  3.887987   \n",
      "4  3.618654  0.171166  0.840254   0.714286  0.027259  0.102677  3.823287   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.104562   0.781497       0.513514    0.007671     0.055252      1   \n",
      "1      0.121922   0.790183       0.541667    0.010497     0.060125      2   \n",
      "2      0.127170   0.799052       0.555556    0.012111     0.067953      3   \n",
      "3      0.130400   0.801657       0.627119    0.014937     0.074296      4   \n",
      "4      0.145741   0.808539       0.555556    0.016149     0.078360      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.023956     0.015115  \n",
      "1  0.032485     0.020594  \n",
      "2  0.040061     0.023706  \n",
      "3  0.048388     0.029180  \n",
      "4  0.052513     0.031385  \n",
      "-- Model : Optimizer:  VGG16 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.580909  0.166607  0.838423   0.711927  0.027649  0.098141  3.799967   \n",
      "1  3.566485  0.180166  0.845653   0.770213  0.031326  0.112238  3.788829   \n",
      "2  3.547928  0.182676  0.848916   0.759551  0.029249  0.113270  3.780252   \n",
      "3  3.532836  0.185358  0.851008   0.744541  0.029508  0.115353  3.776306   \n",
      "4  3.539715  0.182589  0.850808   0.755991  0.030028  0.114626  3.772640   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.148567   0.811996       0.630137    0.018571     0.084847      1   \n",
      "1      0.149374   0.814327       0.638889    0.018571     0.090162      2   \n",
      "2      0.152200   0.815165       0.648649    0.019378     0.093100      3   \n",
      "3      0.151797   0.816749       0.648649    0.019378     0.092341      4   \n",
      "4      0.151797   0.817283       0.675325    0.020993     0.092458      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.053231     0.036078  \n",
      "1  0.060203     0.036093  \n",
      "2  0.056329     0.037632  \n",
      "3  0.056767     0.037632  \n",
      "4  0.057761     0.040720  \n",
      "-- Model : Optimizer:  VGG16 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.526604  0.178009  0.845461   0.752197  0.030500  0.112927  3.768995   \n",
      "1  3.513518  0.190464  0.852373   0.772819  0.032970  0.124496  3.764578   \n",
      "2  3.520186  0.189252  0.852390   0.723320  0.031672  0.117880  3.763000   \n",
      "3  3.512759  0.192368  0.852046   0.757515  0.032710  0.123056  3.760468   \n",
      "4  3.512111  0.186137  0.852584   0.737060  0.030807  0.121187  3.758044   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.153411   0.818098       0.654321    0.021397     0.093166      1   \n",
      "1      0.152604   0.818172       0.666667    0.021801     0.092795      2   \n",
      "2      0.152200   0.817817       0.666667    0.020993     0.093275      3   \n",
      "3      0.153411   0.817942       0.675325    0.020993     0.093832      4   \n",
      "4      0.156237   0.818094       0.684211    0.020993     0.095327      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.058622     0.041439  \n",
      "1  0.063242     0.042220  \n",
      "2  0.060686     0.040705  \n",
      "3  0.062713     0.040720  \n",
      "4  0.059141     0.040736  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.975798  0.145300  0.790238   0.651558  0.016390  0.086473  4.160961   \n",
      "1  3.658235  0.170907  0.834330   0.715976  0.020942  0.101952  3.956576   \n",
      "2  3.582309  0.179214  0.844001   0.737981  0.026566  0.108072  3.912618   \n",
      "3  3.525777  0.187868  0.851176   0.736957  0.029335  0.120256  3.798553   \n",
      "4  3.468683  0.196521  0.858265   0.743682  0.035652  0.129525  3.783568   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.100525   0.768039       0.454545    0.008074     0.044772      1   \n",
      "1      0.119903   0.793938       0.454545    0.014130     0.056194      2   \n",
      "2      0.119903   0.803234       0.366197    0.010497     0.071463      3   \n",
      "3      0.140493   0.814725       0.593023    0.020589     0.084860      4   \n",
      "4      0.145337   0.814050       0.480392    0.019782     0.087785      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.031976     0.015867  \n",
      "1  0.040693     0.027408  \n",
      "2  0.051286     0.020408  \n",
      "3  0.056425     0.039797  \n",
      "4  0.068043     0.037999  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.427621  0.192404  0.852965   0.719272  0.033778  0.131008  3.719645   \n",
      "1  3.360901  0.216597  0.867525   0.769231  0.042402  0.149056  3.700446   \n",
      "2  3.333480  0.221011  0.871163   0.762518  0.046123  0.159255  3.651951   \n",
      "3  3.296332  0.226895  0.873956   0.766216  0.049065  0.165791  3.706738   \n",
      "4  3.251781  0.231222  0.878194   0.772616  0.054690  0.170077  3.665763   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.153411   0.822925       0.538462    0.019782     0.105710      1   \n",
      "1      0.160678   0.822114       0.553571    0.025030     0.114768      2   \n",
      "2      0.175212   0.828514       0.509934    0.031086     0.126516      3   \n",
      "3      0.159467   0.820246       0.526042    0.040775     0.113805      4   \n",
      "4      0.165119   0.825445       0.672727    0.029875     0.125943      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.064525     0.038162  \n",
      "1  0.080374     0.047895  \n",
      "2  0.086985     0.058600  \n",
      "3  0.092225     0.075684  \n",
      "4  0.102150     0.057209  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.224248  0.224827  0.870798   0.766892  0.048528  0.165817  3.609556   \n",
      "1  3.222901  0.235895  0.881247   0.775990  0.054258  0.174179  3.591650   \n",
      "2  3.204113  0.242125  0.882983   0.780755  0.055469  0.181530  3.580936   \n",
      "3  3.196065  0.244289  0.883107   0.765680  0.055988  0.178740  3.575513   \n",
      "4  3.197142  0.240308  0.883496   0.767523  0.056854  0.177594  3.572587   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.176827   0.832142       0.669355    0.033508     0.133420      1   \n",
      "1      0.177231   0.834160       0.664000    0.033508     0.131729      2   \n",
      "2      0.182479   0.835779       0.684211    0.036738     0.134990      3   \n",
      "3      0.185305   0.835507       0.669173    0.035931     0.137534      4   \n",
      "4      0.184901   0.835287       0.676471    0.037142     0.135978      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.091281     0.063822  \n",
      "1  0.101423     0.063797  \n",
      "2  0.103579     0.069732  \n",
      "3  0.104346     0.068199  \n",
      "4  0.105865     0.070417  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.183565  0.232951  0.875756   0.775428  0.054871  0.174077  3.572323   \n",
      "1  3.183507  0.244894  0.884275   0.788416  0.057719  0.183808  3.566069   \n",
      "2  3.181031  0.249394  0.884010   0.773196  0.058411  0.186469  3.561969   \n",
      "3  3.162486  0.253375  0.885556   0.790509  0.059103  0.191507  3.562976   \n",
      "4  3.168334  0.246539  0.885477   0.801802  0.061613  0.181741  3.561540   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.188131   0.834888       0.657143    0.037142     0.137348      1   \n",
      "1      0.190957   0.835859       0.648649    0.038757     0.140575      2   \n",
      "2      0.190957   0.837099       0.659864    0.039160     0.139918      3   \n",
      "3      0.189746   0.836617       0.632653    0.037545     0.139075      4   \n",
      "4      0.189746   0.836636       0.643357    0.037142     0.139183      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.102489     0.070310  \n",
      "1  0.107563     0.073143  \n",
      "2  0.108617     0.073933  \n",
      "3  0.109984     0.070884  \n",
      "4  0.114433     0.070229  \n",
      "-- Model : Optimizer:  Xception : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.556919  0.205729  0.837502   0.699074  0.043041  0.142292  3.932494   \n",
      "1  3.282120  0.236674  0.874227   0.777036  0.050363  0.169472  3.792106   \n",
      "2  3.244908  0.238145  0.878347   0.763838  0.053738  0.176437  3.678868   \n",
      "3  3.198417  0.249308  0.883054   0.760920  0.057286  0.188278  3.607942   \n",
      "4  3.158925  0.254154  0.885234   0.780942  0.061700  0.193332  3.581183   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.123940   0.801609       0.467213    0.023012     0.063787      1   \n",
      "1      0.139685   0.817676       0.392308    0.020589     0.087822      2   \n",
      "2      0.163101   0.824576       0.481481    0.026241     0.111597      3   \n",
      "3      0.186112   0.830580       0.620968    0.031086     0.136042      4   \n",
      "4      0.182479   0.835772       0.609756    0.030279     0.138673      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.081090     0.043863  \n",
      "1  0.094596     0.039125  \n",
      "2  0.100412     0.049770  \n",
      "3  0.106551     0.059208  \n",
      "4  0.114364     0.057692  \n",
      "-- Model : Optimizer:  Xception : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.116048  0.246134  0.879870   0.748644  0.059004  0.193232  3.562387   \n",
      "1  3.093705  0.267480  0.891524   0.753609  0.067757  0.208824  3.513382   \n",
      "2  3.042538  0.272066  0.894676   0.776492  0.075459  0.214373  3.558155   \n",
      "3  3.029984  0.271374  0.896832   0.782295  0.074939  0.213678  3.497826   \n",
      "4  2.995468  0.281931  0.898919   0.782423  0.079353  0.226722  3.454144   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.189342   0.833257       0.680000    0.048042     0.140081      1   \n",
      "1      0.192168   0.842468       0.614583    0.047638     0.141898      2   \n",
      "2      0.197416   0.836351       0.624242    0.041583     0.155882      3   \n",
      "3      0.193783   0.843655       0.619792    0.048042     0.143744      4   \n",
      "4      0.204683   0.846965       0.642534    0.057327     0.160114      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.109386     0.089744  \n",
      "1  0.124335     0.088423  \n",
      "2  0.137550     0.077971  \n",
      "3  0.136776     0.089172  \n",
      "4  0.144092     0.105263  \n",
      "-- Model : Optimizer:  Xception : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  2.963015  0.274140  0.893240   0.767586  0.079313  0.226193  3.452152   \n",
      "1  2.940703  0.289200  0.903935   0.798231  0.085929  0.236828  3.454990   \n",
      "2  2.934787  0.296123  0.903794   0.787540  0.085324  0.239825  3.456948   \n",
      "3  2.923251  0.300623  0.904318   0.786454  0.085410  0.243197  3.455724   \n",
      "4  2.927367  0.295344  0.904138   0.800000  0.088958  0.237800  3.455465   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.210739   0.846315       0.625000    0.054501     0.164520      1   \n",
      "1      0.211143   0.845348       0.633333    0.053694     0.164914      2   \n",
      "2      0.213161   0.845502       0.629108    0.054098     0.165748      3   \n",
      "3      0.211143   0.845726       0.645631    0.053694     0.163494      4   \n",
      "4      0.211143   0.845920       0.654028    0.055713     0.163554      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.143771     0.100260  \n",
      "1  0.155156     0.098995  \n",
      "2  0.153966     0.099628  \n",
      "3  0.154086     0.099143  \n",
      "4  0.160112     0.102679  \n",
      "-- Model : Optimizer:  Xception : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  2.915691  0.283831  0.893879   0.774667  0.082805  0.229485  3.452336   \n",
      "1  2.919096  0.294133  0.906187   0.778029  0.089477  0.239964  3.452262   \n",
      "2  2.916546  0.293527  0.905229   0.807482  0.089650  0.238761  3.445609   \n",
      "3  2.912961  0.298806  0.905120   0.791258  0.090862  0.243139  3.446919   \n",
      "4  2.903958  0.305902  0.904268   0.805275  0.089823  0.249054  3.445722   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.209124   0.846483       0.646226    0.055309     0.160951      1   \n",
      "1      0.209931   0.846173       0.646512    0.056116     0.161977      2   \n",
      "2      0.209931   0.846178       0.641860    0.055713     0.160722      3   \n",
      "3      0.212757   0.845750       0.639269    0.056520     0.163701      4   \n",
      "4      0.215583   0.845792       0.642534    0.057327     0.166190      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.149617     0.101897  \n",
      "1  0.160497     0.103269  \n",
      "2  0.161383     0.102526  \n",
      "3  0.163006     0.103858  \n",
      "4  0.161619     0.105263  \n"
     ]
    }
   ],
   "source": [
    "\t\t\n",
    "\n",
    "for key in tfs.keys():\n",
    "\tprint(\"-- Model : Optimizer: \", key)\n",
    "\tprint(tfs[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tfs to file\n",
    "with open(\"tfs.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(tfs, f)\n",
    "\n",
    "# save tfs to yaml\n",
    "with open(\"tfs.yaml\", \"w\") as f:\n",
    "\tyaml.dump(tfs, f)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save trained models to disk\n",
    "for modelT_name in dic_tranfs_models.keys():\n",
    "\tmodelT = dic_tranfs_models[modelT_name]\n",
    "\tmodelT.save(\"transf_\" + modelT_name + \".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
