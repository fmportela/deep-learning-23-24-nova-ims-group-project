{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref sobre transfer learning:\n",
    "https://keras.io/guides/transfer_learning/\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pydot\n",
    "# ! pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import optimizers\n",
    "import os\n",
    "from tensorflow.keras.utils import image_dataset_from_directory # type: ignore\n",
    "from tensorflow.keras.metrics import (F1Score, Precision, Recall, CategoricalAccuracy,  # type: ignore\n",
    "                                      TruePositives, TrueNegatives, FalsePositives, FalseNegatives) \n",
    "import yaml\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential, layers, initializers, regularizers, optimizers, metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicParams = {}\n",
    "dicParams[\"model_name\"] = \"base_03\"\n",
    "dicParams[\"model_description\"]\t= \"base_03, 150x150, 4Conv, 2MaxPool, 1Dense, 2Dropout, 1Sigmoid, RMSprop(lr=0.001)\"\n",
    "\n",
    "dicParams[\"batch_size\"] = 256\n",
    "#dicParams[\"image_size\"] = (150,150)\n",
    "dicParams[\"image_size\"] = (128,128)\n",
    "dicParams[\"input_shape\"] = dicParams[\"image_size\"] + (3,)\n",
    "#dicParams[\"image_size\"] = (260,225)\n",
    "dicParams[\"epochs\"] = 50\n",
    "dicParams[\"learning_rate\"] = 1e-3\n",
    "\n",
    "dicParams[\"steps_per_epoch\"] = 32\n",
    "dicParams[\"validation_steps\"] = 2\n",
    "dicParams[\"interpolation\"] = \"bilinear\"\n",
    "dicParams[\"color_mode\"] = \"rgb\"\n",
    "\n",
    "dicParams[\"labels\"] = \"inferred\"\n",
    "dicParams[\"seed\"] = 42\n",
    "dicParams[\"crop_to_aspect_ratio\"] = True\n",
    "\n",
    "# dicParams[\"num_classes\"] = 6\n",
    "# dicParams[\"start_dir\"] = \"smalldata\"\n",
    "dicParams[\"num_classes\"] = 114\n",
    "dicParams[\"start_dir\"] = \"data\"\n",
    "\n",
    "#IMAGE_SIZE = (244, 244)\n",
    "#IMAGE_SIZE = (150,150) # - First baseline run\n",
    "# - First baseline run - BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11556 files belonging to 114 classes.\n",
      "Found 2477 files belonging to 114 classes.\n",
      "Found 2477 files belonging to 114 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dicParams[\"start_dir\"], 'train')\n",
    "val_path = os.path.join(dicParams[\"start_dir\"], 'val')\n",
    "test_path = os.path.join(dicParams[\"start_dir\"], 'test')\n",
    "\n",
    "\n",
    "# with the exception of the directory arg all\n",
    "# other args will be the same for each set\n",
    "import_kwargs = {\n",
    "    'labels': dicParams[\"labels\"],\n",
    "    'label_mode': 'categorical',  # if 'categorical' use 'categorical_crossentropy', if 'int' use 'sparse_categorical_crossentropy'\n",
    "    'color_mode': 'rgb',\n",
    "    'batch_size': dicParams[\"batch_size\"],\n",
    "    'image_size': dicParams[\"image_size\"],\n",
    "    'seed': dicParams[\"seed\"],\n",
    "    'interpolation': dicParams[\"interpolation\"],\n",
    "    'crop_to_aspect_ratio': dicParams[\"crop_to_aspect_ratio\"]\n",
    "}\n",
    "\n",
    "\n",
    "# this function returns a tf.data.Dataset object\n",
    "train_data = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    shuffle=True,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "val_data = image_dataset_from_directory(\n",
    "    val_path,\n",
    "    shuffle=False,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "test_data = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    shuffle=False,\n",
    "    **import_kwargs\n",
    ")\n",
    "\n",
    "# making sure all partitions have the same labels in the same order\n",
    "assert train_data.class_names == val_data.class_names == test_data.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an object of type tf.data.Dataset \n",
    "ds_train = train_data\n",
    "\n",
    "ds_val = val_data\n",
    "\n",
    "ds_test = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_base_models = {}\n",
    "\n",
    "dic_base_models[\"ResNet50V2\"] = keras.applications.ResNet50V2(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"ResNet50V2\"].summary()\n",
    "\n",
    "dic_base_models[\"VGG16\"] = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    #input_shape= (128,128,3),\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"VGG16\"].summary()\n",
    "\n",
    "dic_base_models[\"InceptionResNetV2\"] = keras.applications.InceptionResNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False\n",
    ")\n",
    "dic_base_models[\"InceptionResNetV2\"].summary()\n",
    "\n",
    "dic_base_models[\"Xception\"] = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape= dicParams[\"input_shape\"],\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "dic_base_models[\"Xception\"].summary()\n",
    "\n",
    "\n",
    "\n",
    "for base_model in dic_base_models.values():\n",
    "\tbase_model.trainable = False\n",
    "\n",
    "#base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = models.Sequential([layers.RandomFlip(), \n",
    "                           layers.RandomRotation(factor=0.3), \n",
    "                           layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "                           layers.RandomTranslation(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1))\n",
    "                          ])\n",
    "\n",
    "preprocess = models.Sequential([augmentation,layers.BatchNormalization()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "modmetrics = [metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       metrics.AUC(name='AUROC'),\n",
    "                       metrics.Precision(name='precision'),\n",
    "                       metrics.Recall(name='recall'),\n",
    "\t\t\t\t\t   F1Score(average='macro', name=\"F1Macro\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#depois voltar a mudar o numero de epochs\n",
    "def compilation(model, metrics, optimizer=\"RMSprop\", learning_rate = dicParams[\"learning_rate\"], epochs = dicParams[\"epochs\"], verbose=1, loss=\"categorical_crossentropy\"):\n",
    "  if optimizer==\"RMSprop\":\n",
    "    optimizer=optimizers.RMSprop(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adam\":\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate)\n",
    "  elif optimizer==\"SGD\":\n",
    "    optimizer=optimizers.SGD(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Nadam\":\n",
    "    optimizer=optimizers.Nadam(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adadelta\":\n",
    "    optimizer=optimizers.Adadelta(learning_rate=learning_rate)\n",
    "  elif optimizer==\"Adagrad\":\n",
    "    optimizer=optimizers.Adagrad(learning_rate=learning_rate)\n",
    "  else:\n",
    "    print(\"Invalid optimizer\")\n",
    "    return None\n",
    "  \n",
    "  model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "  \n",
    "  history = model.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=verbose)\n",
    "\n",
    "  df_hist = pd.DataFrame.from_dict(history.history)\n",
    "  df_hist[\"Epoch\"] = np.arange(1, len(df_hist) + 1, 1)\n",
    "\n",
    "  #calculating the f1score for each epoch (train and validation)\n",
    "  df_hist['f1_calc'] = 2*(df_hist['precision']*df_hist['recall'])/(df_hist['precision'] + df_hist['recall'])\n",
    "  df_hist['val_f1_calc'] = 2*(df_hist['val_precision']*df_hist['val_recall'])/(df_hist['val_precision']+df_hist['val_recall'])\n",
    "  \n",
    "  return df_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_208 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_203 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 2048)              0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_209 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_204 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_210 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_205 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 128, 128, 3)       12        \n",
      "                                                                 \n",
      " xception (Functional)       (None, 4, 4, 2048)        20861480  \n",
      "                                                                 \n",
      " batch_normalization_211 (B  (None, 4, 4, 2048)        8192      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_206 (Activation  (None, 4, 4, 2048)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_max_pooling2d_3 (Gl  (None, 2048)              0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 114)               233586    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21103270 (80.50 MB)\n",
      "Trainable params: 237688 (928.47 KB)\n",
      "Non-trainable params: 20865582 (79.60 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dic_tranfs_models = {}\n",
    "\n",
    "for base_model_name in dic_base_models.keys():\n",
    "\t#inputs = keras.Input(shape=(128, 128, 3))\n",
    "\tinputs = keras.Input(shape=dicParams[\"input_shape\"])\n",
    "\n",
    "\tx = preprocess(inputs)\n",
    "\tx = base_model(x, training=False)\n",
    "\tx = keras.layers.BatchNormalization()(x)\n",
    "\tx = keras.layers.Activation(\"relu\")(x)\n",
    "\tx = keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "\toutputs = keras.layers.Dense(dicParams[\"num_classes\"],activation=\"softmax\", \n",
    "\t\t\t\t\t\t\t\t\tkernel_initializer=keras.initializers.GlorotNormal(seed=dicParams[\"seed\"]))(x)\n",
    "\tmodelT = keras.Model(inputs, outputs)\n",
    "\n",
    "\tmodelT.summary()\n",
    "\tdic_tranfs_models[base_model_name] = modelT\n",
    "\n",
    "\t# dot_img_file = base_model_name + '.png'\n",
    "\t# keras.utils.plot_model(modelT, to_file=dot_img_file, show_shapes=True)\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  ResNet50V2 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "46/46 [==============================] - 162s 3s/step - loss: 6.3441 - accuracy: 0.0133 - AUROC: 0.5313 - precision: 0.0137 - recall: 0.0011 - F1Macro: 0.0083 - val_loss: 5.4837 - val_accuracy: 0.0194 - val_AUROC: 0.5539 - val_precision: 0.0690 - val_recall: 8.0743e-04 - val_F1Macro: 0.0060\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 160s 3s/step - loss: 5.8838 - accuracy: 0.0214 - AUROC: 0.5716 - precision: 0.0263 - recall: 0.0018 - F1Macro: 0.0114 - val_loss: 5.2845 - val_accuracy: 0.0190 - val_AUROC: 0.5842 - val_precision: 0.0312 - val_recall: 4.0371e-04 - val_F1Macro: 0.0075\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 160s 3s/step - loss: 5.7039 - accuracy: 0.0271 - AUROC: 0.5868 - precision: 0.0496 - recall: 0.0032 - F1Macro: 0.0149 - val_loss: 5.2104 - val_accuracy: 0.0262 - val_AUROC: 0.6044 - val_precision: 0.0488 - val_recall: 8.0743e-04 - val_F1Macro: 0.0111\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 157s 3s/step - loss: 5.5406 - accuracy: 0.0333 - AUROC: 0.6035 - precision: 0.0491 - recall: 0.0029 - F1Macro: 0.0180 - val_loss: 5.1555 - val_accuracy: 0.0371 - val_AUROC: 0.6186 - val_precision: 0.1268 - val_recall: 0.0036 - val_F1Macro: 0.0174\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 157s 3s/step - loss: 5.4125 - accuracy: 0.0369 - AUROC: 0.6185 - precision: 0.0695 - recall: 0.0040 - F1Macro: 0.0201 - val_loss: 5.1387 - val_accuracy: 0.0444 - val_AUROC: 0.6301 - val_precision: 0.1358 - val_recall: 0.0044 - val_F1Macro: 0.0185\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 225s 5s/step - loss: 4.8866 - accuracy: 0.0514 - AUROC: 0.6527 - precision: 0.1463 - recall: 0.0035 - F1Macro: 0.0237 - val_loss: 4.9571 - val_accuracy: 0.0597 - val_AUROC: 0.6642 - val_precision: 0.0758 - val_recall: 0.0020 - val_F1Macro: 0.0179\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 4.5024 - accuracy: 0.0682 - AUROC: 0.7002 - precision: 0.2121 - recall: 0.0012 - F1Macro: 0.0288 - val_loss: 4.6373 - val_accuracy: 0.0618 - val_AUROC: 0.6956 - val_precision: 0.2542 - val_recall: 0.0061 - val_F1Macro: 0.0180\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.3162 - accuracy: 0.0842 - AUROC: 0.7282 - precision: 0.4795 - recall: 0.0030 - F1Macro: 0.0373 - val_loss: 4.4873 - val_accuracy: 0.0747 - val_AUROC: 0.7137 - val_precision: 0.2333 - val_recall: 0.0028 - val_F1Macro: 0.0252\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 4.1956 - accuracy: 0.0967 - AUROC: 0.7478 - precision: 0.4571 - recall: 0.0028 - F1Macro: 0.0436 - val_loss: 4.3582 - val_accuracy: 0.0783 - val_AUROC: 0.7333 - val_precision: 0.3333 - val_recall: 0.0069 - val_F1Macro: 0.0329\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0955 - accuracy: 0.1116 - AUROC: 0.7668 - precision: 0.5536 - recall: 0.0054 - F1Macro: 0.0541 - val_loss: 4.3047 - val_accuracy: 0.0860 - val_AUROC: 0.7454 - val_precision: 0.2614 - val_recall: 0.0093 - val_F1Macro: 0.0343\n",
      "Model:  ResNet50V2 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 234s 5s/step - loss: 4.0527 - accuracy: 0.1083 - AUROC: 0.7702 - precision: 0.4264 - recall: 0.0081 - F1Macro: 0.0508 - val_loss: 4.2232 - val_accuracy: 0.0961 - val_AUROC: 0.7520 - val_precision: 0.4151 - val_recall: 0.0089 - val_F1Macro: 0.0421\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 221s 5s/step - loss: 4.0159 - accuracy: 0.1175 - AUROC: 0.7838 - precision: 0.5855 - recall: 0.0077 - F1Macro: 0.0571 - val_loss: 4.1901 - val_accuracy: 0.0997 - val_AUROC: 0.7566 - val_precision: 0.4000 - val_recall: 0.0065 - val_F1Macro: 0.0473\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.0078 - accuracy: 0.1188 - AUROC: 0.7819 - precision: 0.6129 - recall: 0.0082 - F1Macro: 0.0581 - val_loss: 4.1683 - val_accuracy: 0.1017 - val_AUROC: 0.7584 - val_precision: 0.4516 - val_recall: 0.0057 - val_F1Macro: 0.0500\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.0027 - accuracy: 0.1231 - AUROC: 0.7835 - precision: 0.5969 - recall: 0.0067 - F1Macro: 0.0616 - val_loss: 4.1515 - val_accuracy: 0.1042 - val_AUROC: 0.7611 - val_precision: 0.4444 - val_recall: 0.0048 - val_F1Macro: 0.0524\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9951 - accuracy: 0.1245 - AUROC: 0.7851 - precision: 0.6296 - recall: 0.0074 - F1Macro: 0.0629 - val_loss: 4.1406 - val_accuracy: 0.1058 - val_AUROC: 0.7631 - val_precision: 0.4800 - val_recall: 0.0048 - val_F1Macro: 0.0524\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 3.9849 - accuracy: 0.1225 - AUROC: 0.7835 - precision: 0.5844 - recall: 0.0064 - F1Macro: 0.0634 - val_loss: 4.1298 - val_accuracy: 0.1070 - val_AUROC: 0.7644 - val_precision: 0.4231 - val_recall: 0.0044 - val_F1Macro: 0.0525\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.9654 - accuracy: 0.1250 - AUROC: 0.7897 - precision: 0.6260 - recall: 0.0071 - F1Macro: 0.0644 - val_loss: 4.1225 - val_accuracy: 0.1082 - val_AUROC: 0.7661 - val_precision: 0.4231 - val_recall: 0.0044 - val_F1Macro: 0.0529\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.9613 - accuracy: 0.1237 - AUROC: 0.7898 - precision: 0.6621 - recall: 0.0083 - F1Macro: 0.0619 - val_loss: 4.1137 - val_accuracy: 0.1078 - val_AUROC: 0.7677 - val_precision: 0.5000 - val_recall: 0.0052 - val_F1Macro: 0.0528\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9453 - accuracy: 0.1308 - AUROC: 0.7925 - precision: 0.6667 - recall: 0.0081 - F1Macro: 0.0688 - val_loss: 4.1060 - val_accuracy: 0.1078 - val_AUROC: 0.7682 - val_precision: 0.5000 - val_recall: 0.0048 - val_F1Macro: 0.0522\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.9372 - accuracy: 0.1310 - AUROC: 0.7942 - precision: 0.6618 - recall: 0.0078 - F1Macro: 0.0667 - val_loss: 4.0987 - val_accuracy: 0.1082 - val_AUROC: 0.7693 - val_precision: 0.5000 - val_recall: 0.0052 - val_F1Macro: 0.0527\n",
      "Model:  VGG16 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 4.6239 - accuracy: 0.0711 - AUROC: 0.6977 - precision: 0.2759 - recall: 0.0011 - F1Macro: 0.0336 - val_loss: 4.5051 - val_accuracy: 0.0513 - val_AUROC: 0.7048 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_F1Macro: 0.0138\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 4.2011 - accuracy: 0.0970 - AUROC: 0.7471 - precision: 0.4286 - recall: 7.7882e-04 - F1Macro: 0.0377 - val_loss: 4.3861 - val_accuracy: 0.0593 - val_AUROC: 0.7279 - val_precision: 0.2105 - val_recall: 0.0016 - val_F1Macro: 0.0128\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0907 - accuracy: 0.1112 - AUROC: 0.7673 - precision: 0.5000 - recall: 0.0023 - F1Macro: 0.0473 - val_loss: 4.2417 - val_accuracy: 0.0791 - val_AUROC: 0.7466 - val_precision: 0.6000 - val_recall: 0.0024 - val_F1Macro: 0.0263\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 4.0087 - accuracy: 0.1229 - AUROC: 0.7821 - precision: 0.6848 - recall: 0.0055 - F1Macro: 0.0571 - val_loss: 4.1169 - val_accuracy: 0.0989 - val_AUROC: 0.7673 - val_precision: 0.3636 - val_recall: 0.0032 - val_F1Macro: 0.0454\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.9156 - accuracy: 0.1320 - AUROC: 0.7992 - precision: 0.7124 - recall: 0.0094 - F1Macro: 0.0623 - val_loss: 4.0768 - val_accuracy: 0.1066 - val_AUROC: 0.7737 - val_precision: 0.6000 - val_recall: 0.0061 - val_F1Macro: 0.0519\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.8487 - accuracy: 0.1339 - AUROC: 0.8011 - precision: 0.7037 - recall: 0.0122 - F1Macro: 0.0701 - val_loss: 4.0206 - val_accuracy: 0.1046 - val_AUROC: 0.7815 - val_precision: 0.5135 - val_recall: 0.0077 - val_F1Macro: 0.0553\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.7884 - accuracy: 0.1494 - AUROC: 0.8166 - precision: 0.7245 - recall: 0.0166 - F1Macro: 0.0815 - val_loss: 3.9608 - val_accuracy: 0.1219 - val_AUROC: 0.7902 - val_precision: 0.5417 - val_recall: 0.0105 - val_F1Macro: 0.0601\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.7173 - accuracy: 0.1586 - AUROC: 0.8269 - precision: 0.7301 - recall: 0.0206 - F1Macro: 0.0907 - val_loss: 3.8991 - val_accuracy: 0.1272 - val_AUROC: 0.7991 - val_precision: 0.5556 - val_recall: 0.0121 - val_F1Macro: 0.0680\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6569 - accuracy: 0.1688 - AUROC: 0.8359 - precision: 0.7429 - recall: 0.0250 - F1Macro: 0.1006 - val_loss: 3.8880 - val_accuracy: 0.1304 - val_AUROC: 0.8017 - val_precision: 0.6271 - val_recall: 0.0149 - val_F1Macro: 0.0743\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6187 - accuracy: 0.1712 - AUROC: 0.8403 - precision: 0.7143 - recall: 0.0273 - F1Macro: 0.1027 - val_loss: 3.8233 - val_accuracy: 0.1457 - val_AUROC: 0.8085 - val_precision: 0.5556 - val_recall: 0.0161 - val_F1Macro: 0.0784\n",
      "Model:  VGG16 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 231s 5s/step - loss: 3.5809 - accuracy: 0.1666 - AUROC: 0.8384 - precision: 0.7119 - recall: 0.0276 - F1Macro: 0.0981 - val_loss: 3.8000 - val_accuracy: 0.1486 - val_AUROC: 0.8120 - val_precision: 0.6301 - val_recall: 0.0186 - val_F1Macro: 0.0848\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 221s 5s/step - loss: 3.5665 - accuracy: 0.1802 - AUROC: 0.8457 - precision: 0.7702 - recall: 0.0313 - F1Macro: 0.1122 - val_loss: 3.7888 - val_accuracy: 0.1494 - val_AUROC: 0.8143 - val_precision: 0.6389 - val_recall: 0.0186 - val_F1Macro: 0.0902\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 220s 5s/step - loss: 3.5479 - accuracy: 0.1827 - AUROC: 0.8489 - precision: 0.7596 - recall: 0.0292 - F1Macro: 0.1133 - val_loss: 3.7803 - val_accuracy: 0.1522 - val_AUROC: 0.8152 - val_precision: 0.6486 - val_recall: 0.0194 - val_F1Macro: 0.0931\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5328 - accuracy: 0.1854 - AUROC: 0.8510 - precision: 0.7445 - recall: 0.0295 - F1Macro: 0.1154 - val_loss: 3.7763 - val_accuracy: 0.1518 - val_AUROC: 0.8167 - val_precision: 0.6486 - val_recall: 0.0194 - val_F1Macro: 0.0923\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.5397 - accuracy: 0.1826 - AUROC: 0.8508 - precision: 0.7560 - recall: 0.0300 - F1Macro: 0.1146 - val_loss: 3.7726 - val_accuracy: 0.1518 - val_AUROC: 0.8173 - val_precision: 0.6753 - val_recall: 0.0210 - val_F1Macro: 0.0925\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 229s 5s/step - loss: 3.5266 - accuracy: 0.1780 - AUROC: 0.8455 - precision: 0.7522 - recall: 0.0305 - F1Macro: 0.1129 - val_loss: 3.7690 - val_accuracy: 0.1534 - val_AUROC: 0.8181 - val_precision: 0.6543 - val_recall: 0.0214 - val_F1Macro: 0.0932\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5135 - accuracy: 0.1905 - AUROC: 0.8524 - precision: 0.7728 - recall: 0.0330 - F1Macro: 0.1245 - val_loss: 3.7646 - val_accuracy: 0.1526 - val_AUROC: 0.8182 - val_precision: 0.6667 - val_recall: 0.0218 - val_F1Macro: 0.0928\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5202 - accuracy: 0.1893 - AUROC: 0.8524 - precision: 0.7233 - recall: 0.0317 - F1Macro: 0.1179 - val_loss: 3.7630 - val_accuracy: 0.1522 - val_AUROC: 0.8178 - val_precision: 0.6667 - val_recall: 0.0210 - val_F1Macro: 0.0933\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5128 - accuracy: 0.1924 - AUROC: 0.8520 - precision: 0.7575 - recall: 0.0327 - F1Macro: 0.1231 - val_loss: 3.7605 - val_accuracy: 0.1534 - val_AUROC: 0.8179 - val_precision: 0.6753 - val_recall: 0.0210 - val_F1Macro: 0.0938\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.5121 - accuracy: 0.1861 - AUROC: 0.8526 - precision: 0.7371 - recall: 0.0308 - F1Macro: 0.1212 - val_loss: 3.7580 - val_accuracy: 0.1562 - val_AUROC: 0.8181 - val_precision: 0.6842 - val_recall: 0.0210 - val_F1Macro: 0.0953\n",
      "Model:  InceptionResNetV2 , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.9758 - accuracy: 0.1453 - AUROC: 0.7902 - precision: 0.6516 - recall: 0.0164 - F1Macro: 0.0865 - val_loss: 4.1610 - val_accuracy: 0.1005 - val_AUROC: 0.7680 - val_precision: 0.4545 - val_recall: 0.0081 - val_F1Macro: 0.0448\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.6582 - accuracy: 0.1709 - AUROC: 0.8343 - precision: 0.7160 - recall: 0.0209 - F1Macro: 0.1020 - val_loss: 3.9566 - val_accuracy: 0.1199 - val_AUROC: 0.7939 - val_precision: 0.4545 - val_recall: 0.0141 - val_F1Macro: 0.0562\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.5823 - accuracy: 0.1792 - AUROC: 0.8440 - precision: 0.7380 - recall: 0.0266 - F1Macro: 0.1081 - val_loss: 3.9126 - val_accuracy: 0.1199 - val_AUROC: 0.8032 - val_precision: 0.3662 - val_recall: 0.0105 - val_F1Macro: 0.0715\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.5258 - accuracy: 0.1879 - AUROC: 0.8512 - precision: 0.7370 - recall: 0.0293 - F1Macro: 0.1203 - val_loss: 3.7986 - val_accuracy: 0.1405 - val_AUROC: 0.8147 - val_precision: 0.5930 - val_recall: 0.0206 - val_F1Macro: 0.0849\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.4687 - accuracy: 0.1965 - AUROC: 0.8583 - precision: 0.7437 - recall: 0.0357 - F1Macro: 0.1295 - val_loss: 3.7836 - val_accuracy: 0.1453 - val_AUROC: 0.8141 - val_precision: 0.4804 - val_recall: 0.0198 - val_F1Macro: 0.0878\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.4276 - accuracy: 0.1924 - AUROC: 0.8530 - precision: 0.7193 - recall: 0.0338 - F1Macro: 0.1310 - val_loss: 3.7196 - val_accuracy: 0.1534 - val_AUROC: 0.8229 - val_precision: 0.5385 - val_recall: 0.0198 - val_F1Macro: 0.1057\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.3609 - accuracy: 0.2166 - AUROC: 0.8675 - precision: 0.7692 - recall: 0.0424 - F1Macro: 0.1491 - val_loss: 3.7004 - val_accuracy: 0.1607 - val_AUROC: 0.8221 - val_precision: 0.5536 - val_recall: 0.0250 - val_F1Macro: 0.1148\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.3335 - accuracy: 0.2210 - AUROC: 0.8712 - precision: 0.7625 - recall: 0.0461 - F1Macro: 0.1593 - val_loss: 3.6520 - val_accuracy: 0.1752 - val_AUROC: 0.8285 - val_precision: 0.5099 - val_recall: 0.0311 - val_F1Macro: 0.1265\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.2963 - accuracy: 0.2269 - AUROC: 0.8740 - precision: 0.7662 - recall: 0.0491 - F1Macro: 0.1658 - val_loss: 3.7067 - val_accuracy: 0.1595 - val_AUROC: 0.8202 - val_precision: 0.5260 - val_recall: 0.0408 - val_F1Macro: 0.1138\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2518 - accuracy: 0.2312 - AUROC: 0.8782 - precision: 0.7726 - recall: 0.0547 - F1Macro: 0.1701 - val_loss: 3.6658 - val_accuracy: 0.1651 - val_AUROC: 0.8254 - val_precision: 0.6727 - val_recall: 0.0299 - val_F1Macro: 0.1259\n",
      "Model:  InceptionResNetV2 , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 3.2242 - accuracy: 0.2248 - AUROC: 0.8708 - precision: 0.7669 - recall: 0.0485 - F1Macro: 0.1658 - val_loss: 3.6096 - val_accuracy: 0.1768 - val_AUROC: 0.8321 - val_precision: 0.6694 - val_recall: 0.0335 - val_F1Macro: 0.1334\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2229 - accuracy: 0.2359 - AUROC: 0.8812 - precision: 0.7760 - recall: 0.0543 - F1Macro: 0.1742 - val_loss: 3.5916 - val_accuracy: 0.1772 - val_AUROC: 0.8342 - val_precision: 0.6640 - val_recall: 0.0335 - val_F1Macro: 0.1317\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.2041 - accuracy: 0.2421 - AUROC: 0.8830 - precision: 0.7808 - recall: 0.0555 - F1Macro: 0.1815 - val_loss: 3.5809 - val_accuracy: 0.1825 - val_AUROC: 0.8358 - val_precision: 0.6842 - val_recall: 0.0367 - val_F1Macro: 0.1350\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1961 - accuracy: 0.2443 - AUROC: 0.8831 - precision: 0.7657 - recall: 0.0560 - F1Macro: 0.1787 - val_loss: 3.5755 - val_accuracy: 0.1853 - val_AUROC: 0.8355 - val_precision: 0.6692 - val_recall: 0.0359 - val_F1Macro: 0.1375\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1971 - accuracy: 0.2403 - AUROC: 0.8835 - precision: 0.7675 - recall: 0.0569 - F1Macro: 0.1776 - val_loss: 3.5726 - val_accuracy: 0.1849 - val_AUROC: 0.8353 - val_precision: 0.6765 - val_recall: 0.0371 - val_F1Macro: 0.1360\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 231s 5s/step - loss: 3.1836 - accuracy: 0.2330 - AUROC: 0.8758 - precision: 0.7754 - recall: 0.0549 - F1Macro: 0.1741 - val_loss: 3.5723 - val_accuracy: 0.1881 - val_AUROC: 0.8349 - val_precision: 0.6571 - val_recall: 0.0371 - val_F1Macro: 0.1373\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1835 - accuracy: 0.2449 - AUROC: 0.8843 - precision: 0.7884 - recall: 0.0577 - F1Macro: 0.1838 - val_loss: 3.5661 - val_accuracy: 0.1910 - val_AUROC: 0.8359 - val_precision: 0.6486 - val_recall: 0.0388 - val_F1Macro: 0.1406\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 219s 5s/step - loss: 3.1810 - accuracy: 0.2494 - AUROC: 0.8840 - precision: 0.7732 - recall: 0.0584 - F1Macro: 0.1865 - val_loss: 3.5620 - val_accuracy: 0.1910 - val_AUROC: 0.8371 - val_precision: 0.6599 - val_recall: 0.0392 - val_F1Macro: 0.1399\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1625 - accuracy: 0.2534 - AUROC: 0.8856 - precision: 0.7905 - recall: 0.0591 - F1Macro: 0.1915 - val_loss: 3.5630 - val_accuracy: 0.1897 - val_AUROC: 0.8366 - val_precision: 0.6327 - val_recall: 0.0375 - val_F1Macro: 0.1391\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1683 - accuracy: 0.2465 - AUROC: 0.8855 - precision: 0.8018 - recall: 0.0616 - F1Macro: 0.1817 - val_loss: 3.5615 - val_accuracy: 0.1897 - val_AUROC: 0.8366 - val_precision: 0.6434 - val_recall: 0.0371 - val_F1Macro: 0.1392\n",
      "Model:  Xception , optimizer: Adagrad learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 225s 5s/step - loss: 3.5569 - accuracy: 0.2057 - AUROC: 0.8375 - precision: 0.6991 - recall: 0.0430 - F1Macro: 0.1423 - val_loss: 3.9325 - val_accuracy: 0.1239 - val_AUROC: 0.8016 - val_precision: 0.4672 - val_recall: 0.0230 - val_F1Macro: 0.0638\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.2821 - accuracy: 0.2367 - AUROC: 0.8742 - precision: 0.7770 - recall: 0.0504 - F1Macro: 0.1695 - val_loss: 3.7921 - val_accuracy: 0.1397 - val_AUROC: 0.8177 - val_precision: 0.3923 - val_recall: 0.0206 - val_F1Macro: 0.0878\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 217s 5s/step - loss: 3.2449 - accuracy: 0.2381 - AUROC: 0.8783 - precision: 0.7638 - recall: 0.0537 - F1Macro: 0.1764 - val_loss: 3.6789 - val_accuracy: 0.1631 - val_AUROC: 0.8246 - val_precision: 0.4815 - val_recall: 0.0262 - val_F1Macro: 0.1116\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1984 - accuracy: 0.2493 - AUROC: 0.8831 - precision: 0.7609 - recall: 0.0573 - F1Macro: 0.1883 - val_loss: 3.6079 - val_accuracy: 0.1861 - val_AUROC: 0.8306 - val_precision: 0.6210 - val_recall: 0.0311 - val_F1Macro: 0.1360\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.1589 - accuracy: 0.2542 - AUROC: 0.8852 - precision: 0.7809 - recall: 0.0617 - F1Macro: 0.1933 - val_loss: 3.5812 - val_accuracy: 0.1825 - val_AUROC: 0.8358 - val_precision: 0.6098 - val_recall: 0.0303 - val_F1Macro: 0.1387\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 224s 5s/step - loss: 3.1160 - accuracy: 0.2461 - AUROC: 0.8799 - precision: 0.7486 - recall: 0.0590 - F1Macro: 0.1932 - val_loss: 3.5624 - val_accuracy: 0.1893 - val_AUROC: 0.8333 - val_precision: 0.6800 - val_recall: 0.0480 - val_F1Macro: 0.1401\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0937 - accuracy: 0.2675 - AUROC: 0.8915 - precision: 0.7536 - recall: 0.0678 - F1Macro: 0.2088 - val_loss: 3.5134 - val_accuracy: 0.1922 - val_AUROC: 0.8425 - val_precision: 0.6146 - val_recall: 0.0476 - val_F1Macro: 0.1419\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0425 - accuracy: 0.2721 - AUROC: 0.8947 - precision: 0.7765 - recall: 0.0755 - F1Macro: 0.2144 - val_loss: 3.5582 - val_accuracy: 0.1974 - val_AUROC: 0.8364 - val_precision: 0.6242 - val_recall: 0.0416 - val_F1Macro: 0.1559\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 3.0300 - accuracy: 0.2714 - AUROC: 0.8968 - precision: 0.7823 - recall: 0.0749 - F1Macro: 0.2137 - val_loss: 3.4978 - val_accuracy: 0.1938 - val_AUROC: 0.8437 - val_precision: 0.6198 - val_recall: 0.0480 - val_F1Macro: 0.1437\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9955 - accuracy: 0.2819 - AUROC: 0.8989 - precision: 0.7824 - recall: 0.0794 - F1Macro: 0.2267 - val_loss: 3.4541 - val_accuracy: 0.2047 - val_AUROC: 0.8470 - val_precision: 0.6425 - val_recall: 0.0573 - val_F1Macro: 0.1601\n",
      "Model:  Xception , optimizer: Adadelta learning_rate: 0.001 epochs: 5\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 2.9630 - accuracy: 0.2741 - AUROC: 0.8932 - precision: 0.7676 - recall: 0.0793 - F1Macro: 0.2262 - val_loss: 3.4522 - val_accuracy: 0.2107 - val_AUROC: 0.8463 - val_precision: 0.6250 - val_recall: 0.0545 - val_F1Macro: 0.1645\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9407 - accuracy: 0.2892 - AUROC: 0.9039 - precision: 0.7982 - recall: 0.0859 - F1Macro: 0.2368 - val_loss: 3.4550 - val_accuracy: 0.2111 - val_AUROC: 0.8453 - val_precision: 0.6333 - val_recall: 0.0537 - val_F1Macro: 0.1649\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9348 - accuracy: 0.2961 - AUROC: 0.9038 - precision: 0.7875 - recall: 0.0853 - F1Macro: 0.2398 - val_loss: 3.4569 - val_accuracy: 0.2132 - val_AUROC: 0.8455 - val_precision: 0.6291 - val_recall: 0.0541 - val_F1Macro: 0.1657\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9233 - accuracy: 0.3006 - AUROC: 0.9043 - precision: 0.7865 - recall: 0.0854 - F1Macro: 0.2432 - val_loss: 3.4557 - val_accuracy: 0.2111 - val_AUROC: 0.8457 - val_precision: 0.6456 - val_recall: 0.0537 - val_F1Macro: 0.1635\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9274 - accuracy: 0.2953 - AUROC: 0.9041 - precision: 0.8000 - recall: 0.0890 - F1Macro: 0.2378 - val_loss: 3.4555 - val_accuracy: 0.2111 - val_AUROC: 0.8459 - val_precision: 0.6540 - val_recall: 0.0557 - val_F1Macro: 0.1636\n",
      "Epoch 1/5\n",
      "46/46 [==============================] - 230s 5s/step - loss: 2.9157 - accuracy: 0.2838 - AUROC: 0.8939 - precision: 0.7747 - recall: 0.0828 - F1Macro: 0.2295 - val_loss: 3.4523 - val_accuracy: 0.2091 - val_AUROC: 0.8465 - val_precision: 0.6462 - val_recall: 0.0553 - val_F1Macro: 0.1610\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9191 - accuracy: 0.2941 - AUROC: 0.9062 - precision: 0.7780 - recall: 0.0895 - F1Macro: 0.2400 - val_loss: 3.4523 - val_accuracy: 0.2099 - val_AUROC: 0.8462 - val_precision: 0.6465 - val_recall: 0.0561 - val_F1Macro: 0.1620\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9165 - accuracy: 0.2935 - AUROC: 0.9052 - precision: 0.8075 - recall: 0.0897 - F1Macro: 0.2388 - val_loss: 3.4456 - val_accuracy: 0.2099 - val_AUROC: 0.8462 - val_precision: 0.6419 - val_recall: 0.0557 - val_F1Macro: 0.1607\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9130 - accuracy: 0.2988 - AUROC: 0.9051 - precision: 0.7913 - recall: 0.0909 - F1Macro: 0.2431 - val_loss: 3.4469 - val_accuracy: 0.2128 - val_AUROC: 0.8458 - val_precision: 0.6393 - val_recall: 0.0565 - val_F1Macro: 0.1637\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 218s 5s/step - loss: 2.9040 - accuracy: 0.3059 - AUROC: 0.9043 - precision: 0.8053 - recall: 0.0898 - F1Macro: 0.2491 - val_loss: 3.4457 - val_accuracy: 0.2156 - val_AUROC: 0.8458 - val_precision: 0.6425 - val_recall: 0.0573 - val_F1Macro: 0.1662\n"
     ]
    }
   ],
   "source": [
    "tfs = {}\n",
    "epochsfreeze = 5\n",
    "epochsunfreeze = 5\n",
    "\n",
    "for modelT_name in dic_tranfs_models.keys():\n",
    "\tmodelT = dic_tranfs_models[modelT_name]\n",
    "\n",
    "\t# lstoptimizers = [\"SGD\", \"Adam\", \"Nadam\", \"Adadelta\", \"Adagrad\", \"RMSprop\"]\n",
    "\tlstoptimizers = [\"Adagrad\", \"Adadelta\"]\n",
    "\tfor opt in lstoptimizers:\n",
    "\t\tprint(\"Model: \", modelT_name, \", optimizer:\", opt, \"learning_rate:\", dicParams[\"learning_rate\"], \"epochs:\", epochsfreeze)\n",
    "\t\t\n",
    "\t\tres = compilation(modelT, metrics = modmetrics, optimizer=opt, learning_rate = dicParams[\"learning_rate\"], epochs=epochsfreeze)\n",
    "\t\ttfs[modelT_name + \" : \" + opt] = res\n",
    "\n",
    "\t\t# Unfreeze all layers\n",
    "\t\tmodelT.trainable = True\n",
    "\t\t#modelT.summary()\n",
    "\t\t# dot_img_file = modelT_name + '_unfreeze.png'\n",
    "\t\t# keras.utils.plot_model(modelT, to_file=dot_img_file, show_shapes=True)\n",
    "\t\tres2 = compilation(modelT, metrics = modmetrics, optimizer=opt, learning_rate = dicParams[\"learning_rate\"], epochs=epochsunfreeze)\n",
    "\t\ttfs[modelT_name + \" : \" + opt + \" : Unfrozen\"] = res2\n",
    "\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Model : Optimizer:  ResNet50V2 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  6.344058  0.013326  0.531298   0.013684  0.001125  0.008345  5.483694   \n",
      "1  5.883828  0.021374  0.571639   0.026283  0.001817  0.011369  5.284451   \n",
      "2  5.703894  0.027085  0.586788   0.049598  0.003202  0.014883  5.210447   \n",
      "3  5.540602  0.033316  0.603510   0.049133  0.002942  0.018042  5.155463   \n",
      "4  5.412502  0.036864  0.618502   0.069486  0.003981  0.020078  5.138659   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.019378   0.553916       0.068966    0.000807     0.005968      1   \n",
      "1      0.018975   0.584177       0.031250    0.000404     0.007472      2   \n",
      "2      0.026241   0.604449       0.048780    0.000807     0.011133      3   \n",
      "3      0.037142   0.618578       0.126761    0.003633     0.017423      4   \n",
      "4      0.044409   0.630097       0.135802    0.004441     0.018504      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.002079     0.001596  \n",
      "1  0.003399     0.000797  \n",
      "2  0.006015     0.001589  \n",
      "3  0.005552     0.007064  \n",
      "4  0.007530     0.008600  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.886632  0.051379  0.652731   0.146269  0.003492  0.023730  4.957102   \n",
      "1  4.502393  0.068190  0.700245   0.212121  0.001211  0.028798  4.637305   \n",
      "2  4.316155  0.084199  0.728198   0.479452  0.003029  0.037303  4.487314   \n",
      "3  4.195566  0.096746  0.747843   0.457143  0.002769  0.043649  4.358168   \n",
      "4  4.095477  0.111630  0.766792   0.553571  0.005365  0.054092  4.304657   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.059750   0.664234       0.075758    0.002019     0.017879      1   \n",
      "1      0.061768   0.695587       0.254237    0.006056     0.017976      2   \n",
      "2      0.074687   0.713728       0.233333    0.002826     0.025186      3   \n",
      "3      0.078321   0.733292       0.333333    0.006863     0.032913      4   \n",
      "4      0.085991   0.745443       0.261364    0.009285     0.034304      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.006821     0.003932  \n",
      "1  0.002409     0.011830  \n",
      "2  0.006019     0.005584  \n",
      "3  0.005505     0.013449  \n",
      "4  0.010627     0.017934  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.052679  0.108316  0.770154   0.426415  0.008052  0.050783  4.223194   \n",
      "1  4.015875  0.117515  0.783760   0.585526  0.007702  0.057057  4.190098   \n",
      "2  4.007836  0.118813  0.781933   0.612903  0.008221  0.058135  4.168252   \n",
      "3  4.002694  0.123053  0.783487   0.596899  0.006663  0.061570  4.151511   \n",
      "4  3.995120  0.124524  0.785067   0.629630  0.007355  0.062869  4.140556   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.096084   0.751998       0.415094    0.008882     0.042084      1   \n",
      "1      0.099717   0.756644       0.400000    0.006459     0.047326      2   \n",
      "2      0.101736   0.758413       0.451613    0.005652     0.050046      3   \n",
      "3      0.104158   0.761095       0.444444    0.004845     0.052387      4   \n",
      "4      0.105773   0.763117       0.480000    0.004845     0.052364      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.015806     0.017391  \n",
      "1  0.015203     0.012714  \n",
      "2  0.016224     0.011164  \n",
      "3  0.013179     0.009585  \n",
      "4  0.014541     0.009592  \n",
      "-- Model : Optimizer:  ResNet50V2 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.984897  0.122497  0.783546   0.584416  0.006413  0.063436  4.129817   \n",
      "1  3.965362  0.124957  0.789720   0.625954  0.007096  0.064430  4.122509   \n",
      "2  3.961303  0.123745  0.789806   0.662069  0.008307  0.061945  4.113707   \n",
      "3  3.945269  0.130841  0.792501   0.666667  0.008134  0.068797  4.105951   \n",
      "4  3.937173  0.131014  0.794172   0.661765  0.007788  0.066740  4.098728   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.106984   0.764421       0.423077    0.004441     0.052532      1   \n",
      "1      0.108195   0.766088       0.423077    0.004441     0.052895      2   \n",
      "2      0.107792   0.767724       0.500000    0.005248     0.052765      3   \n",
      "3      0.107792   0.768160       0.500000    0.004845     0.052247      4   \n",
      "4      0.108195   0.769259       0.500000    0.005248     0.052668      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.012688     0.008789  \n",
      "1  0.014033     0.008789  \n",
      "2  0.016409     0.010388  \n",
      "3  0.016072     0.009596  \n",
      "4  0.015395     0.010388  \n",
      "-- Model : Optimizer:  VGG16 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  4.623932  0.071118  0.697739   0.275862  0.001140  0.033573  4.505054   \n",
      "1  4.201077  0.097006  0.747111   0.428571  0.000779  0.037663  4.386085   \n",
      "2  4.090651  0.111198  0.767319   0.500000  0.002336  0.047256  4.241683   \n",
      "3  4.008705  0.122880  0.782125   0.684783  0.005452  0.057070  4.116879   \n",
      "4  3.915635  0.131966  0.799221   0.712418  0.009432  0.062295  4.076803   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.051272   0.704776       0.000000    0.000000     0.013758      1   \n",
      "1      0.059346   0.727923       0.210526    0.001615     0.012754      2   \n",
      "2      0.079128   0.746564       0.600000    0.002422     0.026296      3   \n",
      "3      0.098910   0.767303       0.363636    0.003230     0.045365      4   \n",
      "4      0.106581   0.773653       0.600000    0.006056     0.051932      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.002271          NaN  \n",
      "1  0.001555     0.003205  \n",
      "2  0.004651     0.004825  \n",
      "3  0.010817     0.006403  \n",
      "4  0.018618     0.011990  \n",
      "-- Model : Optimizer:  VGG16 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.848671  0.133899  0.801087   0.703704  0.012186  0.070099  4.020621   \n",
      "1  3.788385  0.149446  0.816641   0.724528  0.016615  0.081484  3.960827   \n",
      "2  3.717280  0.158619  0.826878   0.730061  0.020595  0.090698  3.899065   \n",
      "3  3.656883  0.168830  0.835863   0.742931  0.025009  0.100585  3.887987   \n",
      "4  3.618654  0.171166  0.840254   0.714286  0.027259  0.102677  3.823287   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.104562   0.781497       0.513514    0.007671     0.055252      1   \n",
      "1      0.121922   0.790183       0.541667    0.010497     0.060125      2   \n",
      "2      0.127170   0.799052       0.555556    0.012111     0.067953      3   \n",
      "3      0.130400   0.801657       0.627119    0.014937     0.074296      4   \n",
      "4      0.145741   0.808539       0.555556    0.016149     0.078360      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.023956     0.015115  \n",
      "1  0.032485     0.020594  \n",
      "2  0.040061     0.023706  \n",
      "3  0.048388     0.029180  \n",
      "4  0.052513     0.031385  \n",
      "-- Model : Optimizer:  VGG16 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.580909  0.166607  0.838423   0.711927  0.027649  0.098141  3.799967   \n",
      "1  3.566485  0.180166  0.845653   0.770213  0.031326  0.112238  3.788829   \n",
      "2  3.547928  0.182676  0.848916   0.759551  0.029249  0.113270  3.780252   \n",
      "3  3.532836  0.185358  0.851008   0.744541  0.029508  0.115353  3.776306   \n",
      "4  3.539715  0.182589  0.850808   0.755991  0.030028  0.114626  3.772640   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.148567   0.811996       0.630137    0.018571     0.084847      1   \n",
      "1      0.149374   0.814327       0.638889    0.018571     0.090162      2   \n",
      "2      0.152200   0.815165       0.648649    0.019378     0.093100      3   \n",
      "3      0.151797   0.816749       0.648649    0.019378     0.092341      4   \n",
      "4      0.151797   0.817283       0.675325    0.020993     0.092458      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.053231     0.036078  \n",
      "1  0.060203     0.036093  \n",
      "2  0.056329     0.037632  \n",
      "3  0.056767     0.037632  \n",
      "4  0.057761     0.040720  \n",
      "-- Model : Optimizer:  VGG16 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.526604  0.178009  0.845461   0.752197  0.030500  0.112927  3.768995   \n",
      "1  3.513518  0.190464  0.852373   0.772819  0.032970  0.124496  3.764578   \n",
      "2  3.520186  0.189252  0.852390   0.723320  0.031672  0.117880  3.763000   \n",
      "3  3.512759  0.192368  0.852046   0.757515  0.032710  0.123056  3.760468   \n",
      "4  3.512111  0.186137  0.852584   0.737060  0.030807  0.121187  3.758044   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.153411   0.818098       0.654321    0.021397     0.093166      1   \n",
      "1      0.152604   0.818172       0.666667    0.021801     0.092795      2   \n",
      "2      0.152200   0.817817       0.666667    0.020993     0.093275      3   \n",
      "3      0.153411   0.817942       0.675325    0.020993     0.093832      4   \n",
      "4      0.156237   0.818094       0.684211    0.020993     0.095327      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.058622     0.041439  \n",
      "1  0.063242     0.042220  \n",
      "2  0.060686     0.040705  \n",
      "3  0.062713     0.040720  \n",
      "4  0.059141     0.040736  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.975798  0.145300  0.790238   0.651558  0.016390  0.086473  4.160961   \n",
      "1  3.658235  0.170907  0.834330   0.715976  0.020942  0.101952  3.956576   \n",
      "2  3.582309  0.179214  0.844001   0.737981  0.026566  0.108072  3.912618   \n",
      "3  3.525777  0.187868  0.851176   0.736957  0.029335  0.120256  3.798553   \n",
      "4  3.468683  0.196521  0.858265   0.743682  0.035652  0.129525  3.783568   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.100525   0.768039       0.454545    0.008074     0.044772      1   \n",
      "1      0.119903   0.793938       0.454545    0.014130     0.056194      2   \n",
      "2      0.119903   0.803234       0.366197    0.010497     0.071463      3   \n",
      "3      0.140493   0.814725       0.593023    0.020589     0.084860      4   \n",
      "4      0.145337   0.814050       0.480392    0.019782     0.087785      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.031976     0.015867  \n",
      "1  0.040693     0.027408  \n",
      "2  0.051286     0.020408  \n",
      "3  0.056425     0.039797  \n",
      "4  0.068043     0.037999  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.427621  0.192404  0.852965   0.719272  0.033778  0.131008  3.719645   \n",
      "1  3.360901  0.216597  0.867525   0.769231  0.042402  0.149056  3.700446   \n",
      "2  3.333480  0.221011  0.871163   0.762518  0.046123  0.159255  3.651951   \n",
      "3  3.296332  0.226895  0.873956   0.766216  0.049065  0.165791  3.706738   \n",
      "4  3.251781  0.231222  0.878194   0.772616  0.054690  0.170077  3.665763   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.153411   0.822925       0.538462    0.019782     0.105710      1   \n",
      "1      0.160678   0.822114       0.553571    0.025030     0.114768      2   \n",
      "2      0.175212   0.828514       0.509934    0.031086     0.126516      3   \n",
      "3      0.159467   0.820246       0.526042    0.040775     0.113805      4   \n",
      "4      0.165119   0.825445       0.672727    0.029875     0.125943      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.064525     0.038162  \n",
      "1  0.080374     0.047895  \n",
      "2  0.086985     0.058600  \n",
      "3  0.092225     0.075684  \n",
      "4  0.102150     0.057209  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.224248  0.224827  0.870798   0.766892  0.048528  0.165817  3.609556   \n",
      "1  3.222901  0.235895  0.881247   0.775990  0.054258  0.174179  3.591650   \n",
      "2  3.204113  0.242125  0.882983   0.780755  0.055469  0.181530  3.580936   \n",
      "3  3.196065  0.244289  0.883107   0.765680  0.055988  0.178740  3.575513   \n",
      "4  3.197142  0.240308  0.883496   0.767523  0.056854  0.177594  3.572587   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.176827   0.832142       0.669355    0.033508     0.133420      1   \n",
      "1      0.177231   0.834160       0.664000    0.033508     0.131729      2   \n",
      "2      0.182479   0.835779       0.684211    0.036738     0.134990      3   \n",
      "3      0.185305   0.835507       0.669173    0.035931     0.137534      4   \n",
      "4      0.184901   0.835287       0.676471    0.037142     0.135978      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.091281     0.063822  \n",
      "1  0.101423     0.063797  \n",
      "2  0.103579     0.069732  \n",
      "3  0.104346     0.068199  \n",
      "4  0.105865     0.070417  \n",
      "-- Model : Optimizer:  InceptionResNetV2 : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.183565  0.232951  0.875756   0.775428  0.054871  0.174077  3.572323   \n",
      "1  3.183507  0.244894  0.884275   0.788416  0.057719  0.183808  3.566069   \n",
      "2  3.181031  0.249394  0.884010   0.773196  0.058411  0.186469  3.561969   \n",
      "3  3.162486  0.253375  0.885556   0.790509  0.059103  0.191507  3.562976   \n",
      "4  3.168334  0.246539  0.885477   0.801802  0.061613  0.181741  3.561540   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.188131   0.834888       0.657143    0.037142     0.137348      1   \n",
      "1      0.190957   0.835859       0.648649    0.038757     0.140575      2   \n",
      "2      0.190957   0.837099       0.659864    0.039160     0.139918      3   \n",
      "3      0.189746   0.836617       0.632653    0.037545     0.139075      4   \n",
      "4      0.189746   0.836636       0.643357    0.037142     0.139183      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.102489     0.070310  \n",
      "1  0.107563     0.073143  \n",
      "2  0.108617     0.073933  \n",
      "3  0.109984     0.070884  \n",
      "4  0.114433     0.070229  \n",
      "-- Model : Optimizer:  Xception : Adagrad\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.556919  0.205729  0.837502   0.699074  0.043041  0.142292  3.932494   \n",
      "1  3.282120  0.236674  0.874227   0.777036  0.050363  0.169472  3.792106   \n",
      "2  3.244908  0.238145  0.878347   0.763838  0.053738  0.176437  3.678868   \n",
      "3  3.198417  0.249308  0.883054   0.760920  0.057286  0.188278  3.607942   \n",
      "4  3.158925  0.254154  0.885234   0.780942  0.061700  0.193332  3.581183   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.123940   0.801609       0.467213    0.023012     0.063787      1   \n",
      "1      0.139685   0.817676       0.392308    0.020589     0.087822      2   \n",
      "2      0.163101   0.824576       0.481481    0.026241     0.111597      3   \n",
      "3      0.186112   0.830580       0.620968    0.031086     0.136042      4   \n",
      "4      0.182479   0.835772       0.609756    0.030279     0.138673      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.081090     0.043863  \n",
      "1  0.094596     0.039125  \n",
      "2  0.100412     0.049770  \n",
      "3  0.106551     0.059208  \n",
      "4  0.114364     0.057692  \n",
      "-- Model : Optimizer:  Xception : Adagrad : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  3.116048  0.246134  0.879870   0.748644  0.059004  0.193232  3.562387   \n",
      "1  3.093705  0.267480  0.891524   0.753609  0.067757  0.208824  3.513382   \n",
      "2  3.042538  0.272066  0.894676   0.776492  0.075459  0.214373  3.558155   \n",
      "3  3.029984  0.271374  0.896832   0.782295  0.074939  0.213678  3.497826   \n",
      "4  2.995468  0.281931  0.898919   0.782423  0.079353  0.226722  3.454144   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.189342   0.833257       0.680000    0.048042     0.140081      1   \n",
      "1      0.192168   0.842468       0.614583    0.047638     0.141898      2   \n",
      "2      0.197416   0.836351       0.624242    0.041583     0.155882      3   \n",
      "3      0.193783   0.843655       0.619792    0.048042     0.143744      4   \n",
      "4      0.204683   0.846965       0.642534    0.057327     0.160114      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.109386     0.089744  \n",
      "1  0.124335     0.088423  \n",
      "2  0.137550     0.077971  \n",
      "3  0.136776     0.089172  \n",
      "4  0.144092     0.105263  \n",
      "-- Model : Optimizer:  Xception : Adadelta\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  2.963015  0.274140  0.893240   0.767586  0.079313  0.226193  3.452152   \n",
      "1  2.940703  0.289200  0.903935   0.798231  0.085929  0.236828  3.454990   \n",
      "2  2.934787  0.296123  0.903794   0.787540  0.085324  0.239825  3.456948   \n",
      "3  2.923251  0.300623  0.904318   0.786454  0.085410  0.243197  3.455724   \n",
      "4  2.927367  0.295344  0.904138   0.800000  0.088958  0.237800  3.455465   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.210739   0.846315       0.625000    0.054501     0.164520      1   \n",
      "1      0.211143   0.845348       0.633333    0.053694     0.164914      2   \n",
      "2      0.213161   0.845502       0.629108    0.054098     0.165748      3   \n",
      "3      0.211143   0.845726       0.645631    0.053694     0.163494      4   \n",
      "4      0.211143   0.845920       0.654028    0.055713     0.163554      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.143771     0.100260  \n",
      "1  0.155156     0.098995  \n",
      "2  0.153966     0.099628  \n",
      "3  0.154086     0.099143  \n",
      "4  0.160112     0.102679  \n",
      "-- Model : Optimizer:  Xception : Adadelta : Unfrozen\n",
      "       loss  accuracy     AUROC  precision    recall   F1Macro  val_loss  \\\n",
      "0  2.915691  0.283831  0.893879   0.774667  0.082805  0.229485  3.452336   \n",
      "1  2.919096  0.294133  0.906187   0.778029  0.089477  0.239964  3.452262   \n",
      "2  2.916546  0.293527  0.905229   0.807482  0.089650  0.238761  3.445609   \n",
      "3  2.912961  0.298806  0.905120   0.791258  0.090862  0.243139  3.446919   \n",
      "4  2.903958  0.305902  0.904268   0.805275  0.089823  0.249054  3.445722   \n",
      "\n",
      "   val_accuracy  val_AUROC  val_precision  val_recall  val_F1Macro  Epoch  \\\n",
      "0      0.209124   0.846483       0.646226    0.055309     0.160951      1   \n",
      "1      0.209931   0.846173       0.646512    0.056116     0.161977      2   \n",
      "2      0.209931   0.846178       0.641860    0.055713     0.160722      3   \n",
      "3      0.212757   0.845750       0.639269    0.056520     0.163701      4   \n",
      "4      0.215583   0.845792       0.642534    0.057327     0.166190      5   \n",
      "\n",
      "    f1_calc  val_f1_calc  \n",
      "0  0.149617     0.101897  \n",
      "1  0.160497     0.103269  \n",
      "2  0.161383     0.102526  \n",
      "3  0.163006     0.103858  \n",
      "4  0.161619     0.105263  \n"
     ]
    }
   ],
   "source": [
    "\t\t\n",
    "\n",
    "for key in tfs.keys():\n",
    "\tprint(\"-- Model : Optimizer: \", key)\n",
    "\tprint(tfs[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tfs to file\n",
    "with open(\"tfs.pkl\", \"wb\") as f:\n",
    "\tpickle.dump(tfs, f)\n",
    "\n",
    "# save tfs to yaml\n",
    "with open(\"tfs.yaml\", \"w\") as f:\n",
    "\tyaml.dump(tfs, f)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\DL2024Proj\\GroupProject\\.venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save trained models to disk\n",
    "for modelT_name in dic_tranfs_models.keys():\n",
    "\tmodelT = dic_tranfs_models[modelT_name]\n",
    "\tmodelT.save(\"transf_\" + modelT_name + \".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
